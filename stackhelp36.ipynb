{"cells":[{"cell_type":"code","source":["from pyspark.sql import functions as F\nfrom pyspark.sql.types import *\nfrom pyspark.sql.window import Window"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["list=[[1 ,  2   ,2016   , 5  , 9  ],\n     [2  , 4   ,2016    ,5  , 9   ],\n     [3 ,  0   ,2016    ,5  , 9 ], \n     [4  ,4   ,2016    ,5   ,9   ],\n     [5  , 0   ,2016   , 5  , 9  ],\n     [6  , 2  , 2016    ,5  , 9  ],\n     [1   ,0   ,2016    ,6  , 9  ],\n     [2   ,2  , 2016    ,6  , 9   ],\n     [3   ,0  , 2016    ,6  , 9   ],\n     [4   ,0  , 2016    ,6  , 9   ],\n     [5   ,0  , 2016    ,6  , 9    ],\n     [6   ,0  , 2016    ,6  , 9    ],\n     [6   ,8  , 2016    ,7  , 9    ],\n     [1   ,0  , 2016    ,0  , 10   ],\n     [2   ,2  ,2016    ,0   ,10   ],\n     [3   ,2  , 2016    ,0  , 10   ],\n     [4   ,2  , 2016    ,0  , 10   ],\n     [5   ,6   ,2016    ,0  , 10   ],\n     [6   ,0  , 2016    ,0  , 10   ],\n     [1   ,0  , 2016    ,1  , 10  ],\n     [2   ,0   ,2016    ,1  ,10   ],\n     [3   ,2   ,2016    ,1  , 10   ],\n     [4   ,0  , 2016    ,1  , 10   ],\n      [5   ,0   ,2016    ,1 ,  10  ],\n      [6   ,0   ,2016    ,1   ,10  ],\n      [1   ,0  ,2016    ,2   ,10  ],\n      [2   ,6   ,2016    ,2  , 10  ],\n      [3   ,0   ,2016    ,2  , 10  ],\n      [4   ,4   ,2016    ,2  , 10  ],\n      [5   ,0   ,2016    ,2  , 10  ],\n      [6   ,2   ,2016    ,2  , 10  ],\n      [1   ,0   ,2016    ,3  , 10  ],\n[2   ,0   ,2016    ,3   ,10  ],\n[3   ,0  ,2016    ,3  , 10  ],\n[4   ,4   ,2016    ,3   ,10  ],\n[5   ,0   ,2016    ,3   ,10  ],\n[6   ,0   ,2016    ,3   ,10  ],\n[1   ,0   ,2016    ,4   ,10  ],\n[2   ,0   ,2016    ,4   ,10  ],\n[3   ,2   ,2016    ,4   ,10  ],\n[4   ,4   ,2016    ,4   ,10  ],\n[5   ,0   ,2016   ,4   ,10  ],\n[6   ,2   ,2016   , 4   ,10  ],\n[1   ,4   ,2016    ,5   ,10  ],\n[2   ,0   ,2016    ,5  , 10  ],\n[3   ,0   ,2016   ,5   ,10  ],\n[4   ,8   ,2016    ,5   ,10  ],\n[5   ,0   ,2016    ,5   ,10  ],\n[6   ,0   ,2016    ,5   ,10  ],\n[1   ,0   ,2016    ,6   ,10  ],\n[2   ,0   ,2016    ,6   ,10  ],\n[3   ,0   ,2016    ,6   ,10  ],\n[4   ,6   ,2016    ,6   ,10  ],\n[5   ,2   ,2016    ,6   ,10  ],\n[6   ,6   ,2016    ,6   ,10 ],\n[1   ,0   ,2020    ,0   ,8   ],\n[2   ,2   ,2020    ,0   ,8   ],\n[3   ,0   ,2020   , 0   ,8   ],\n[4   ,0   ,2020    ,0   ,8   ],\n[5   ,0   ,2020    ,0   ,8   ],\n[6   ,2   ,2020    ,0   ,8  ],\n[1   ,0   ,2020    ,1   ,8  ],\n[2   ,0   ,2020    ,1   ,8   ],\n[3   ,0   ,2020    ,1   ,8   ],\n[4   ,0   ,2020    ,1   ,8   ],\n[5   ,0   ,2020    ,1   ,8 ],\n[6   ,0  , 2020    ,1   ,8   ],\n[1   ,0   ,2020    ,2   ,8   ],\n[2   ,0  , 2020    ,2   ,8   ],\n[3   ,0  , 2020    ,2   ,8   ],\n[4   ,0   ,2020    ,2   ,8   ],\n[5   ,0   ,2020    ,2   ,8   ],\n[6   ,0   ,2020    ,2  , 8   ],\n[1   ,0  , 2020   , 3   ,8  ],\n[2   ,0  , 2020    ,3   ,8   ],\n[3   ,0  , 2020    ,3  , 8  ],\n[4   ,0  , 2020    ,3   ,8   ],\n[5   ,0  , 2020    ,3   ,8   ],\n[6   ,0  , 2020    ,3   ,8   ],\n[1   ,0  , 2020    ,4   ,8   ],\n[2   ,0  , 2020    ,4   ,8   ],\n[3   ,2  , 2020    ,4   ,8   ],\n[4   ,0  , 2020    ,4   ,8   ],\n[5   ,0  , 2020    ,4  , 8  ],\n[6   ,0  , 2020    ,4   ,8   ],\n[5   ,2  , 2020    ,5  , 8   ],\n[6   ,4  , 2020    ,5  , 8  ],\n[3   ,4  , 2020    ,6  , 8   ],\n[3   ,4  , 2020    ,0  , 8  ]]\ndf=spark.createDataFrame(list,['ID' , 'qty' ,'year','day','month'])\ndf.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+---+----+---+-----+\n ID|qty|year|day|month|\n+---+---+----+---+-----+\n  1|  2|2016|  5|    9|\n  2|  4|2016|  5|    9|\n  3|  0|2016|  5|    9|\n  4|  4|2016|  5|    9|\n  5|  0|2016|  5|    9|\n  6|  2|2016|  5|    9|\n  1|  0|2016|  6|    9|\n  2|  2|2016|  6|    9|\n  3|  0|2016|  6|    9|\n  4|  0|2016|  6|    9|\n  5|  0|2016|  6|    9|\n  6|  0|2016|  6|    9|\n  6|  8|2016|  7|    9|\n  1|  0|2016|  0|   10|\n  2|  2|2016|  0|   10|\n  3|  2|2016|  0|   10|\n  4|  2|2016|  0|   10|\n  5|  6|2016|  0|   10|\n  6|  0|2016|  0|   10|\n  1|  0|2016|  1|   10|\n+---+---+----+---+-----+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":2},{"cell_type":"code","source":["list=[[1 ,  2   ,2016   , 5  , 9  ],\n     [2  , 4   ,2016    ,5  , 9   ],\n     [3 ,  0   ,2016    ,5  , 9 ], \n     [4  ,4   ,2016    ,5   ,9   ],\n     [5  , 0   ,2016   , 5  , 9  ],\n     [6  , 2  , 2016    ,5  , 9  ],\n     [1   ,0   ,2016    ,6  , 9  ],\n     [2   ,2  , 2016    ,6  , 9   ],\n     [3   ,0  , 2016    ,6  , 9   ],\n     [4   ,0  , 2016    ,6  , 9   ],\n     [5   ,0  , 2016    ,6  , 9    ],\n     [6   ,0  , 2016    ,6  , 9    ],\n     [6   ,8  , 2016    ,7  , 9    ],\n     [1   ,0  , 2016    ,1  , 10   ],\n     [2   ,2  ,2016    ,1   ,10   ],\n     [3   ,2  , 2016    ,1  , 10   ],\n     [4   ,2  , 2016    ,1  , 10   ],\n     [5   ,6   ,2016    ,1  , 10   ],\n     [6   ,0  , 2016    ,1  , 10   ],\n     [1   ,0  , 2016    ,1  , 10  ],\n     [2   ,0   ,2016    ,1  ,10   ],\n     [3   ,2   ,2016    ,1  , 10   ],\n     [4   ,0  , 2016    ,1  , 10   ],\n      [5   ,0   ,2016    ,1 ,  10  ],\n      [6   ,0   ,2016    ,1   ,10  ],\n      [1   ,0  ,2016    ,2   ,10  ],\n      [2   ,6   ,2016    ,2  , 10  ],\n      [3   ,0   ,2016    ,2  , 10  ],\n      [4   ,4   ,2016    ,2  , 10  ],\n      [5   ,0   ,2016    ,2  , 10  ],\n      [6   ,2   ,2016    ,2  , 10  ],\n      [1   ,0   ,2016    ,3  , 10  ],\n[2   ,0   ,2016    ,3   ,10  ],\n[3   ,0  ,2016    ,3  , 10  ],\n[4   ,4   ,2016    ,3   ,10  ],\n[5   ,0   ,2016    ,3   ,10  ],\n[6   ,0   ,2016    ,3   ,10  ],\n[1   ,0   ,2016    ,4   ,10  ],\n[2   ,0   ,2016    ,4   ,10  ],\n[3   ,2   ,2016    ,4   ,10  ],\n[4   ,4   ,2016    ,4   ,10  ],\n[5   ,0   ,2016   ,4   ,10  ],\n[6   ,2   ,2016   , 4   ,10  ],\n[1   ,4   ,2016    ,5   ,10  ],\n[2   ,0   ,2016    ,5  , 10  ],\n[3   ,0   ,2016   ,5   ,10  ],\n[4   ,8   ,2016    ,5   ,10  ],\n[5   ,0   ,2016    ,5   ,10  ],\n[6   ,0   ,2016    ,5   ,10  ],\n[1   ,0   ,2016    ,6   ,10  ],\n[2   ,0   ,2016    ,6   ,10  ],\n[3   ,0   ,2016    ,6   ,10  ],\n[4   ,6   ,2016    ,6   ,10  ],\n[5   ,2   ,2016    ,6   ,10  ],\n[6   ,6   ,2016    ,6   ,10 ],\n[1   ,0   ,2020    ,1   ,8   ],\n[2   ,2   ,2020    ,1   ,8   ],\n[3   ,0   ,2020   , 1   ,8   ],\n[4   ,0   ,2020    ,1   ,8   ],\n[5   ,0   ,2020    ,1   ,8   ],\n[6   ,2   ,2020    ,1   ,8  ],\n[1   ,0   ,2020    ,1   ,8  ],\n[2   ,0   ,2020    ,1   ,8   ],\n[3   ,0   ,2020    ,1   ,8   ],\n[4   ,0   ,2020    ,1   ,8   ],\n[5   ,0   ,2020    ,1   ,8 ],\n[6   ,0  , 2020    ,1   ,8   ],\n[1   ,0   ,2020    ,2   ,8   ],\n[2   ,0  , 2020    ,2   ,8   ],\n[3   ,0  , 2020    ,2   ,8   ],\n[4   ,0   ,2020    ,2   ,8   ],\n[5   ,0   ,2020    ,2   ,8   ],\n[6   ,0   ,2020    ,2  , 8   ],\n[1   ,0  , 2020   , 3   ,8  ],\n[2   ,0  , 2020    ,3   ,8   ],\n[3   ,0  , 2020    ,3  , 8  ],\n[4   ,0  , 2020    ,3   ,8   ],\n[5   ,0  , 2020    ,3   ,8   ],\n[6   ,0  , 2020    ,3   ,8   ],\n[1   ,0  , 2020    ,4   ,8   ],\n[2   ,0  , 2020    ,4   ,8   ],\n[3   ,2  , 2020    ,4   ,8   ],\n[4   ,0  , 2020    ,4   ,8   ],\n[5   ,0  , 2020    ,4  , 8  ],\n[6   ,0  , 2020    ,4   ,8   ],\n[5   ,2  , 2020    ,5  , 8   ],\n[6   ,4  , 2020    ,5  , 8  ],\n[3   ,4  , 2020    ,6  , 8   ],\n[3   ,4  , 2020    ,1  , 8  ]]\ndf=spark.createDataFrame(list,['ID' , 'qty' ,'year','day','month'])\ndf.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+---+----+---+-----+\n ID|qty|year|day|month|\n+---+---+----+---+-----+\n  1|  2|2016|  5|    9|\n  2|  4|2016|  5|    9|\n  3|  0|2016|  5|    9|\n  4|  4|2016|  5|    9|\n  5|  0|2016|  5|    9|\n  6|  2|2016|  5|    9|\n  1|  0|2016|  6|    9|\n  2|  2|2016|  6|    9|\n  3|  0|2016|  6|    9|\n  4|  0|2016|  6|    9|\n  5|  0|2016|  6|    9|\n  6|  0|2016|  6|    9|\n  6|  8|2016|  7|    9|\n  1|  0|2016|  1|   10|\n  2|  2|2016|  1|   10|\n  3|  2|2016|  1|   10|\n  4|  2|2016|  1|   10|\n  5|  6|2016|  1|   10|\n  6|  0|2016|  1|   10|\n  1|  0|2016|  1|   10|\n+---+---+----+---+-----+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":3},{"cell_type":"code","source":["df=df.withColumn(\"date\", F.to_date(F.concat_ws(\"-\",(*(x for x in [\"year\",\"month\",\"day\"]))),\"yyyy-m-d\"))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["from pyspark.sql import functions as F\nfrom pyspark.sql.window import Window\n\nw1=Window().partitionBy(\"year\")\nw2=Window().partitionBy(\"year\",\"month\")\nw3=Window().partitionBy(\"year\",\"month\",\"day\")\nw4=Window().partitionBy(\"year\",\"month\",\"day\").orderBy(\"day\")\nw5=Window().partitionBy(\"year\").orderBy(\"month\",\"day\")\n\ndisplay(df.withColumn(\"total_Sales_year\", F.sum(\"qty\").over(w1))\\\n  .withColumn(\"total_sales_by_day\", F.sum(\"qty\").over(w3))\\\n  .withColumn(\"total_sales_week\", F.sum(\"qty\").over(w2))\\\n  .withColumn(\"rownum\", F.row_number().over(w4))\\\n  .withColumn(\"newday\", F.when(F.col(\"rownum\")!=1, F.lit(0)).otherwise(F.col(\"total_sales_by_day\")))\\\n  .withColumn(\"total_sales_year_to_day\", F.sum(\"newday\").over(w5)).drop(\"rownum\",\"newday\"))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>ID</th><th>qty</th><th>year</th><th>day</th><th>month</th><th>date</th><th>total_Sales_year</th><th>total_sales_by_day</th><th>total_sales_week</th><th>total_sales_year_to_day</th></tr></thead><tbody><tr><td>1</td><td>2</td><td>2016</td><td>5</td><td>9</td><td>2016-01-05</td><td>86</td><td>12</td><td>22</td><td>12</td></tr><tr><td>2</td><td>4</td><td>2016</td><td>5</td><td>9</td><td>2016-01-05</td><td>86</td><td>12</td><td>22</td><td>12</td></tr><tr><td>3</td><td>0</td><td>2016</td><td>5</td><td>9</td><td>2016-01-05</td><td>86</td><td>12</td><td>22</td><td>12</td></tr><tr><td>4</td><td>4</td><td>2016</td><td>5</td><td>9</td><td>2016-01-05</td><td>86</td><td>12</td><td>22</td><td>12</td></tr><tr><td>5</td><td>0</td><td>2016</td><td>5</td><td>9</td><td>2016-01-05</td><td>86</td><td>12</td><td>22</td><td>12</td></tr><tr><td>6</td><td>2</td><td>2016</td><td>5</td><td>9</td><td>2016-01-05</td><td>86</td><td>12</td><td>22</td><td>12</td></tr><tr><td>1</td><td>0</td><td>2016</td><td>6</td><td>9</td><td>2016-01-06</td><td>86</td><td>2</td><td>22</td><td>14</td></tr><tr><td>2</td><td>2</td><td>2016</td><td>6</td><td>9</td><td>2016-01-06</td><td>86</td><td>2</td><td>22</td><td>14</td></tr><tr><td>3</td><td>0</td><td>2016</td><td>6</td><td>9</td><td>2016-01-06</td><td>86</td><td>2</td><td>22</td><td>14</td></tr><tr><td>4</td><td>0</td><td>2016</td><td>6</td><td>9</td><td>2016-01-06</td><td>86</td><td>2</td><td>22</td><td>14</td></tr><tr><td>5</td><td>0</td><td>2016</td><td>6</td><td>9</td><td>2016-01-06</td><td>86</td><td>2</td><td>22</td><td>14</td></tr><tr><td>6</td><td>0</td><td>2016</td><td>6</td><td>9</td><td>2016-01-06</td><td>86</td><td>2</td><td>22</td><td>14</td></tr><tr><td>6</td><td>8</td><td>2016</td><td>7</td><td>9</td><td>2016-01-07</td><td>86</td><td>8</td><td>22</td><td>22</td></tr><tr><td>1</td><td>0</td><td>2016</td><td>1</td><td>10</td><td>2016-01-01</td><td>86</td><td>14</td><td>64</td><td>36</td></tr><tr><td>2</td><td>2</td><td>2016</td><td>1</td><td>10</td><td>2016-01-01</td><td>86</td><td>14</td><td>64</td><td>36</td></tr><tr><td>3</td><td>2</td><td>2016</td><td>1</td><td>10</td><td>2016-01-01</td><td>86</td><td>14</td><td>64</td><td>36</td></tr><tr><td>4</td><td>2</td><td>2016</td><td>1</td><td>10</td><td>2016-01-01</td><td>86</td><td>14</td><td>64</td><td>36</td></tr><tr><td>5</td><td>6</td><td>2016</td><td>1</td><td>10</td><td>2016-01-01</td><td>86</td><td>14</td><td>64</td><td>36</td></tr><tr><td>6</td><td>0</td><td>2016</td><td>1</td><td>10</td><td>2016-01-01</td><td>86</td><td>14</td><td>64</td><td>36</td></tr><tr><td>1</td><td>0</td><td>2016</td><td>1</td><td>10</td><td>2016-01-01</td><td>86</td><td>14</td><td>64</td><td>36</td></tr><tr><td>2</td><td>0</td><td>2016</td><td>1</td><td>10</td><td>2016-01-01</td><td>86</td><td>14</td><td>64</td><td>36</td></tr><tr><td>3</td><td>2</td><td>2016</td><td>1</td><td>10</td><td>2016-01-01</td><td>86</td><td>14</td><td>64</td><td>36</td></tr><tr><td>4</td><td>0</td><td>2016</td><td>1</td><td>10</td><td>2016-01-01</td><td>86</td><td>14</td><td>64</td><td>36</td></tr><tr><td>5</td><td>0</td><td>2016</td><td>1</td><td>10</td><td>2016-01-01</td><td>86</td><td>14</td><td>64</td><td>36</td></tr><tr><td>6</td><td>0</td><td>2016</td><td>1</td><td>10</td><td>2016-01-01</td><td>86</td><td>14</td><td>64</td><td>36</td></tr><tr><td>1</td><td>0</td><td>2016</td><td>2</td><td>10</td><td>2016-01-02</td><td>86</td><td>12</td><td>64</td><td>48</td></tr><tr><td>2</td><td>6</td><td>2016</td><td>2</td><td>10</td><td>2016-01-02</td><td>86</td><td>12</td><td>64</td><td>48</td></tr><tr><td>3</td><td>0</td><td>2016</td><td>2</td><td>10</td><td>2016-01-02</td><td>86</td><td>12</td><td>64</td><td>48</td></tr><tr><td>4</td><td>4</td><td>2016</td><td>2</td><td>10</td><td>2016-01-02</td><td>86</td><td>12</td><td>64</td><td>48</td></tr><tr><td>5</td><td>0</td><td>2016</td><td>2</td><td>10</td><td>2016-01-02</td><td>86</td><td>12</td><td>64</td><td>48</td></tr><tr><td>6</td><td>2</td><td>2016</td><td>2</td><td>10</td><td>2016-01-02</td><td>86</td><td>12</td><td>64</td><td>48</td></tr><tr><td>1</td><td>0</td><td>2016</td><td>3</td><td>10</td><td>2016-01-03</td><td>86</td><td>4</td><td>64</td><td>52</td></tr><tr><td>2</td><td>0</td><td>2016</td><td>3</td><td>10</td><td>2016-01-03</td><td>86</td><td>4</td><td>64</td><td>52</td></tr><tr><td>3</td><td>0</td><td>2016</td><td>3</td><td>10</td><td>2016-01-03</td><td>86</td><td>4</td><td>64</td><td>52</td></tr><tr><td>4</td><td>4</td><td>2016</td><td>3</td><td>10</td><td>2016-01-03</td><td>86</td><td>4</td><td>64</td><td>52</td></tr><tr><td>5</td><td>0</td><td>2016</td><td>3</td><td>10</td><td>2016-01-03</td><td>86</td><td>4</td><td>64</td><td>52</td></tr><tr><td>6</td><td>0</td><td>2016</td><td>3</td><td>10</td><td>2016-01-03</td><td>86</td><td>4</td><td>64</td><td>52</td></tr><tr><td>1</td><td>0</td><td>2016</td><td>4</td><td>10</td><td>2016-01-04</td><td>86</td><td>8</td><td>64</td><td>60</td></tr><tr><td>2</td><td>0</td><td>2016</td><td>4</td><td>10</td><td>2016-01-04</td><td>86</td><td>8</td><td>64</td><td>60</td></tr><tr><td>3</td><td>2</td><td>2016</td><td>4</td><td>10</td><td>2016-01-04</td><td>86</td><td>8</td><td>64</td><td>60</td></tr><tr><td>4</td><td>4</td><td>2016</td><td>4</td><td>10</td><td>2016-01-04</td><td>86</td><td>8</td><td>64</td><td>60</td></tr><tr><td>5</td><td>0</td><td>2016</td><td>4</td><td>10</td><td>2016-01-04</td><td>86</td><td>8</td><td>64</td><td>60</td></tr><tr><td>6</td><td>2</td><td>2016</td><td>4</td><td>10</td><td>2016-01-04</td><td>86</td><td>8</td><td>64</td><td>60</td></tr><tr><td>1</td><td>4</td><td>2016</td><td>5</td><td>10</td><td>2016-01-05</td><td>86</td><td>12</td><td>64</td><td>72</td></tr><tr><td>2</td><td>0</td><td>2016</td><td>5</td><td>10</td><td>2016-01-05</td><td>86</td><td>12</td><td>64</td><td>72</td></tr><tr><td>3</td><td>0</td><td>2016</td><td>5</td><td>10</td><td>2016-01-05</td><td>86</td><td>12</td><td>64</td><td>72</td></tr><tr><td>4</td><td>8</td><td>2016</td><td>5</td><td>10</td><td>2016-01-05</td><td>86</td><td>12</td><td>64</td><td>72</td></tr><tr><td>5</td><td>0</td><td>2016</td><td>5</td><td>10</td><td>2016-01-05</td><td>86</td><td>12</td><td>64</td><td>72</td></tr><tr><td>6</td><td>0</td><td>2016</td><td>5</td><td>10</td><td>2016-01-05</td><td>86</td><td>12</td><td>64</td><td>72</td></tr><tr><td>1</td><td>0</td><td>2016</td><td>6</td><td>10</td><td>2016-01-06</td><td>86</td><td>14</td><td>64</td><td>86</td></tr><tr><td>2</td><td>0</td><td>2016</td><td>6</td><td>10</td><td>2016-01-06</td><td>86</td><td>14</td><td>64</td><td>86</td></tr><tr><td>3</td><td>0</td><td>2016</td><td>6</td><td>10</td><td>2016-01-06</td><td>86</td><td>14</td><td>64</td><td>86</td></tr><tr><td>4</td><td>6</td><td>2016</td><td>6</td><td>10</td><td>2016-01-06</td><td>86</td><td>14</td><td>64</td><td>86</td></tr><tr><td>5</td><td>2</td><td>2016</td><td>6</td><td>10</td><td>2016-01-06</td><td>86</td><td>14</td><td>64</td><td>86</td></tr><tr><td>6</td><td>6</td><td>2016</td><td>6</td><td>10</td><td>2016-01-06</td><td>86</td><td>14</td><td>64</td><td>86</td></tr><tr><td>1</td><td>0</td><td>2020</td><td>1</td><td>8</td><td>2020-01-01</td><td>20</td><td>8</td><td>20</td><td>8</td></tr><tr><td>2</td><td>2</td><td>2020</td><td>1</td><td>8</td><td>2020-01-01</td><td>20</td><td>8</td><td>20</td><td>8</td></tr><tr><td>3</td><td>0</td><td>2020</td><td>1</td><td>8</td><td>2020-01-01</td><td>20</td><td>8</td><td>20</td><td>8</td></tr><tr><td>4</td><td>0</td><td>2020</td><td>1</td><td>8</td><td>2020-01-01</td><td>20</td><td>8</td><td>20</td><td>8</td></tr><tr><td>5</td><td>0</td><td>2020</td><td>1</td><td>8</td><td>2020-01-01</td><td>20</td><td>8</td><td>20</td><td>8</td></tr><tr><td>6</td><td>2</td><td>2020</td><td>1</td><td>8</td><td>2020-01-01</td><td>20</td><td>8</td><td>20</td><td>8</td></tr><tr><td>1</td><td>0</td><td>2020</td><td>1</td><td>8</td><td>2020-01-01</td><td>20</td><td>8</td><td>20</td><td>8</td></tr><tr><td>2</td><td>0</td><td>2020</td><td>1</td><td>8</td><td>2020-01-01</td><td>20</td><td>8</td><td>20</td><td>8</td></tr><tr><td>3</td><td>0</td><td>2020</td><td>1</td><td>8</td><td>2020-01-01</td><td>20</td><td>8</td><td>20</td><td>8</td></tr><tr><td>4</td><td>0</td><td>2020</td><td>1</td><td>8</td><td>2020-01-01</td><td>20</td><td>8</td><td>20</td><td>8</td></tr><tr><td>5</td><td>0</td><td>2020</td><td>1</td><td>8</td><td>2020-01-01</td><td>20</td><td>8</td><td>20</td><td>8</td></tr><tr><td>6</td><td>0</td><td>2020</td><td>1</td><td>8</td><td>2020-01-01</td><td>20</td><td>8</td><td>20</td><td>8</td></tr><tr><td>3</td><td>4</td><td>2020</td><td>1</td><td>8</td><td>2020-01-01</td><td>20</td><td>8</td><td>20</td><td>8</td></tr><tr><td>1</td><td>0</td><td>2020</td><td>2</td><td>8</td><td>2020-01-02</td><td>20</td><td>0</td><td>20</td><td>8</td></tr><tr><td>2</td><td>0</td><td>2020</td><td>2</td><td>8</td><td>2020-01-02</td><td>20</td><td>0</td><td>20</td><td>8</td></tr><tr><td>3</td><td>0</td><td>2020</td><td>2</td><td>8</td><td>2020-01-02</td><td>20</td><td>0</td><td>20</td><td>8</td></tr><tr><td>4</td><td>0</td><td>2020</td><td>2</td><td>8</td><td>2020-01-02</td><td>20</td><td>0</td><td>20</td><td>8</td></tr><tr><td>5</td><td>0</td><td>2020</td><td>2</td><td>8</td><td>2020-01-02</td><td>20</td><td>0</td><td>20</td><td>8</td></tr><tr><td>6</td><td>0</td><td>2020</td><td>2</td><td>8</td><td>2020-01-02</td><td>20</td><td>0</td><td>20</td><td>8</td></tr><tr><td>1</td><td>0</td><td>2020</td><td>3</td><td>8</td><td>2020-01-03</td><td>20</td><td>0</td><td>20</td><td>8</td></tr><tr><td>2</td><td>0</td><td>2020</td><td>3</td><td>8</td><td>2020-01-03</td><td>20</td><td>0</td><td>20</td><td>8</td></tr><tr><td>3</td><td>0</td><td>2020</td><td>3</td><td>8</td><td>2020-01-03</td><td>20</td><td>0</td><td>20</td><td>8</td></tr><tr><td>4</td><td>0</td><td>2020</td><td>3</td><td>8</td><td>2020-01-03</td><td>20</td><td>0</td><td>20</td><td>8</td></tr><tr><td>5</td><td>0</td><td>2020</td><td>3</td><td>8</td><td>2020-01-03</td><td>20</td><td>0</td><td>20</td><td>8</td></tr><tr><td>6</td><td>0</td><td>2020</td><td>3</td><td>8</td><td>2020-01-03</td><td>20</td><td>0</td><td>20</td><td>8</td></tr><tr><td>1</td><td>0</td><td>2020</td><td>4</td><td>8</td><td>2020-01-04</td><td>20</td><td>2</td><td>20</td><td>10</td></tr><tr><td>2</td><td>0</td><td>2020</td><td>4</td><td>8</td><td>2020-01-04</td><td>20</td><td>2</td><td>20</td><td>10</td></tr><tr><td>3</td><td>2</td><td>2020</td><td>4</td><td>8</td><td>2020-01-04</td><td>20</td><td>2</td><td>20</td><td>10</td></tr><tr><td>4</td><td>0</td><td>2020</td><td>4</td><td>8</td><td>2020-01-04</td><td>20</td><td>2</td><td>20</td><td>10</td></tr><tr><td>5</td><td>0</td><td>2020</td><td>4</td><td>8</td><td>2020-01-04</td><td>20</td><td>2</td><td>20</td><td>10</td></tr><tr><td>6</td><td>0</td><td>2020</td><td>4</td><td>8</td><td>2020-01-04</td><td>20</td><td>2</td><td>20</td><td>10</td></tr><tr><td>5</td><td>2</td><td>2020</td><td>5</td><td>8</td><td>2020-01-05</td><td>20</td><td>6</td><td>20</td><td>16</td></tr><tr><td>6</td><td>4</td><td>2020</td><td>5</td><td>8</td><td>2020-01-05</td><td>20</td><td>6</td><td>20</td><td>16</td></tr><tr><td>3</td><td>4</td><td>2020</td><td>6</td><td>8</td><td>2020-01-06</td><td>20</td><td>4</td><td>20</td><td>20</td></tr></tbody></table></div>"]}}],"execution_count":5},{"cell_type":"code","source":["from pyspark.sql import functions as F\nfrom pyspark.sql.window import Window\n\nw1=Window().partitionBy(\"year\")\nw2=Window().partitionBy(\"year\",\"week\")\nw3=Window().partitionBy(\"year\",\"week\",\"day\")\nw4=Window().partitionBy(\"year\",\"week\",\"day\").orderBy(\"day\")\nw5=Window().partitionBy(\"year\").orderBy(\"week\",\"day\")\n\ndisplay(df.withColumn(\"total_Sales_year\", F.sum(\"qty\").over(w1))\\\n  .withColumn(\"total_sales_by_day\", F.sum(\"qty\").over(w3))\\\n  .withColumn(\"total_sales_week\", F.sum(\"qty\").over(w2))\\\n  .withColumn(\"rownum\", F.row_number().over(w4))\\\n  .withColumn(\"newday\", F.when(F.col(\"rownum\")!=1, F.lit(0)).otherwise(F.col(\"total_sales_by_day\")))\\\n  .withColumn(\"total_sales_year_to_day\", F.sum(\"newday\").over(w5)).drop(\"rownum\",\"newday\"))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     62</span>         <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">---&gt; 63</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     64</span>         <span class=\"ansi-green-fg\">except</span> py4j<span class=\"ansi-blue-fg\">.</span>protocol<span class=\"ansi-blue-fg\">.</span>Py4JJavaError <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py</span> in <span class=\"ansi-cyan-fg\">get_return_value</span><span class=\"ansi-blue-fg\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    327</span>                     <span class=\"ansi-blue-fg\">&#34;An error occurred while calling {0}{1}{2}.\\n&#34;</span><span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-fg\">--&gt; 328</span><span class=\"ansi-red-fg\">                     format(target_id, &#34;.&#34;, name), value)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    329</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-red-fg\">Py4JJavaError</span>: An error occurred while calling o667.withColumn.\n: org.apache.spark.sql.AnalysisException: cannot resolve &#39;`week`&#39; given input columns: [qty, total_Sales_year, date, year, month, day, ID];;\n&#39;Project [ID#9363L, qty#9364L, year#9365L, day#9366L, month#9367L, date#9415, total_Sales_year#9423L, sum(qty#9364L) windowspecdefinition(year#9365L, &#39;week, day#9366L, specifiedwindowframe(RowFrame, unboundedpreceding$(), unboundedfollowing$())) AS total_sales_by_day#9432]\n+- Window [ID#9363L, qty#9364L, year#9365L, day#9366L, month#9367L, date#9415, sum(qty#9364L) windowspecdefinition(year#9365L, specifiedwindowframe(RowFrame, unboundedpreceding$(), unboundedfollowing$())) AS total_Sales_year#9423L], [year#9365L]\n   +- Project [ID#9363L, qty#9364L, year#9365L, day#9366L, month#9367L, date#9415]\n      +- Project [ID#9363L, qty#9364L, year#9365L, day#9366L, month#9367L, to_date(concat_ws(-, &#39;year, &#39;month, &#39;day), Some(yyyy-m-d)) AS date#9415]\n         +- LogicalRDD [ID#9363L, qty#9364L, year#9365L, day#9366L, month#9367L], false\n\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$3.applyOrElse(CheckAnalysis.scala:120)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$3.applyOrElse(CheckAnalysis.scala:111)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$6.apply(TreeNode.scala:303)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$6.apply(TreeNode.scala:303)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:76)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:302)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$5.apply(TreeNode.scala:300)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$5.apply(TreeNode.scala:300)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.org$apache$spark$sql$catalyst$trees$TreeNode$$mapChild$2(TreeNode.scala:322)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$8$$anonfun$apply$13.apply(TreeNode.scala:381)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:104)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$8.apply(TreeNode.scala:381)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:207)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:351)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:300)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$5.apply(TreeNode.scala:300)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$5.apply(TreeNode.scala:300)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$8.apply(TreeNode.scala:353)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:207)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:351)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:300)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$5.apply(TreeNode.scala:300)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$5.apply(TreeNode.scala:300)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$8.apply(TreeNode.scala:353)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:207)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:351)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:300)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:94)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:94)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$3.apply(QueryPlan.scala:106)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$3.apply(QueryPlan.scala:106)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:76)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:105)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:117)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1$2.apply(QueryPlan.scala:122)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.immutable.List.map(List.scala:296)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:122)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$4.apply(QueryPlan.scala:127)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:207)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:127)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:94)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:111)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:89)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:147)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$class.checkAnalysis(CheckAnalysis.scala:89)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:103)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:117)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:114)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:114)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$analyzed$1.apply(QueryExecution.scala:86)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$analyzed$1.apply(QueryExecution.scala:83)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:83)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:83)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:75)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:81)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withPlan(Dataset.scala:3534)\n\tat org.apache.spark.sql.Dataset.select(Dataset.scala:1362)\n\tat org.apache.spark.sql.Dataset.withColumns(Dataset.scala:2327)\n\tat org.apache.spark.sql.Dataset.withColumn(Dataset.scala:2294)\n\tat sun.reflect.GeneratedMethodAccessor185.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\n\n\nDuring handling of the above exception, another exception occurred:\n\n<span class=\"ansi-red-fg\">AnalysisException</span>                         Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3617736183930617&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      9</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     10</span> display(df.withColumn(&#34;total_Sales_year&#34;, F.sum(&#34;qty&#34;).over(w1))\\\n<span class=\"ansi-green-fg\">---&gt; 11</span><span class=\"ansi-red-fg\">   </span><span class=\"ansi-blue-fg\">.</span>withColumn<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;total_sales_by_day&#34;</span><span class=\"ansi-blue-fg\">,</span> F<span class=\"ansi-blue-fg\">.</span>sum<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;qty&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>over<span class=\"ansi-blue-fg\">(</span>w3<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-red-fg\">\\</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     12</span>   <span class=\"ansi-blue-fg\">.</span>withColumn<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;total_sales_week&#34;</span><span class=\"ansi-blue-fg\">,</span> F<span class=\"ansi-blue-fg\">.</span>sum<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;qty&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>over<span class=\"ansi-blue-fg\">(</span>w2<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-red-fg\">\\</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     13</span>   <span class=\"ansi-blue-fg\">.</span>withColumn<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;rownum&#34;</span><span class=\"ansi-blue-fg\">,</span> F<span class=\"ansi-blue-fg\">.</span>row_number<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>over<span class=\"ansi-blue-fg\">(</span>w4<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-red-fg\">\\</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/dataframe.py</span> in <span class=\"ansi-cyan-fg\">withColumn</span><span class=\"ansi-blue-fg\">(self, colName, col)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   2023</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-intense-fg ansi-bold\">   2024</span>         <span class=\"ansi-green-fg\">assert</span> isinstance<span class=\"ansi-blue-fg\">(</span>col<span class=\"ansi-blue-fg\">,</span> Column<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;col should be Column&#34;</span>\n<span class=\"ansi-green-fg\">-&gt; 2025</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> DataFrame<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jdf<span class=\"ansi-blue-fg\">.</span>withColumn<span class=\"ansi-blue-fg\">(</span>colName<span class=\"ansi-blue-fg\">,</span> col<span class=\"ansi-blue-fg\">.</span>_jc<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>sql_ctx<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   2026</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   2027</span>     <span class=\"ansi-blue-fg\">@</span>ignore_unicode_prefix\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1255</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1256</span>         return_value = get_return_value(\n<span class=\"ansi-green-fg\">-&gt; 1257</span><span class=\"ansi-red-fg\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1258</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1259</span>         <span class=\"ansi-green-fg\">for</span> temp_arg <span class=\"ansi-green-fg\">in</span> temp_args<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     67</span>                                              e.java_exception.getStackTrace()))\n<span class=\"ansi-green-intense-fg ansi-bold\">     68</span>             <span class=\"ansi-green-fg\">if</span> s<span class=\"ansi-blue-fg\">.</span>startswith<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;org.apache.spark.sql.AnalysisException: &#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">---&gt; 69</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">raise</span> AnalysisException<span class=\"ansi-blue-fg\">(</span>s<span class=\"ansi-blue-fg\">.</span>split<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;: &#39;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> stackTrace<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     70</span>             <span class=\"ansi-green-fg\">if</span> s<span class=\"ansi-blue-fg\">.</span>startswith<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;org.apache.spark.sql.catalyst.analysis&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     71</span>                 <span class=\"ansi-green-fg\">raise</span> AnalysisException<span class=\"ansi-blue-fg\">(</span>s<span class=\"ansi-blue-fg\">.</span>split<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;: &#39;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> stackTrace<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">AnalysisException</span>: &#34;cannot resolve &#39;`week`&#39; given input columns: [qty, total_Sales_year, date, year, month, day, ID];;\\n&#39;Project [ID#9363L, qty#9364L, year#9365L, day#9366L, month#9367L, date#9415, total_Sales_year#9423L, sum(qty#9364L) windowspecdefinition(year#9365L, &#39;week, day#9366L, specifiedwindowframe(RowFrame, unboundedpreceding$(), unboundedfollowing$())) AS total_sales_by_day#9432]\\n+- Window [ID#9363L, qty#9364L, year#9365L, day#9366L, month#9367L, date#9415, sum(qty#9364L) windowspecdefinition(year#9365L, specifiedwindowframe(RowFrame, unboundedpreceding$(), unboundedfollowing$())) AS total_Sales_year#9423L], [year#9365L]\\n   +- Project [ID#9363L, qty#9364L, year#9365L, day#9366L, month#9367L, date#9415]\\n      +- Project [ID#9363L, qty#9364L, year#9365L, day#9366L, month#9367L, to_date(concat_ws(-, &#39;year, &#39;month, &#39;day), Some(yyyy-m-d)) AS date#9415]\\n         +- LogicalRDD [ID#9363L, qty#9364L, year#9365L, day#9366L, month#9367L], false\\n&#34;</div>"]}}],"execution_count":6},{"cell_type":"code","source":["display(df1)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>ID</th><th>qty</th><th>year</th><th>day</th><th>week</th><th>total_Sales_year</th><th>total_sales_by_day</th><th>total_sales_week</th><th>total_sales_year_to_day</th></tr></thead><tbody><tr><td>1</td><td>2</td><td>2016</td><td>5</td><td>9</td><td>78</td><td>12</td><td>14</td><td>12</td></tr><tr><td>2</td><td>4</td><td>2016</td><td>5</td><td>9</td><td>78</td><td>12</td><td>14</td><td>12</td></tr><tr><td>3</td><td>0</td><td>2016</td><td>5</td><td>9</td><td>78</td><td>12</td><td>14</td><td>12</td></tr><tr><td>4</td><td>4</td><td>2016</td><td>5</td><td>9</td><td>78</td><td>12</td><td>14</td><td>12</td></tr><tr><td>5</td><td>0</td><td>2016</td><td>5</td><td>9</td><td>78</td><td>12</td><td>14</td><td>12</td></tr><tr><td>6</td><td>2</td><td>2016</td><td>5</td><td>9</td><td>78</td><td>12</td><td>14</td><td>12</td></tr><tr><td>1</td><td>0</td><td>2016</td><td>6</td><td>9</td><td>78</td><td>2</td><td>14</td><td>14</td></tr><tr><td>2</td><td>2</td><td>2016</td><td>6</td><td>9</td><td>78</td><td>2</td><td>14</td><td>14</td></tr><tr><td>3</td><td>0</td><td>2016</td><td>6</td><td>9</td><td>78</td><td>2</td><td>14</td><td>14</td></tr><tr><td>4</td><td>0</td><td>2016</td><td>6</td><td>9</td><td>78</td><td>2</td><td>14</td><td>14</td></tr><tr><td>5</td><td>0</td><td>2016</td><td>6</td><td>9</td><td>78</td><td>2</td><td>14</td><td>14</td></tr><tr><td>6</td><td>0</td><td>2016</td><td>6</td><td>9</td><td>78</td><td>2</td><td>14</td><td>14</td></tr><tr><td>1</td><td>0</td><td>2016</td><td>0</td><td>10</td><td>78</td><td>12</td><td>64</td><td>26</td></tr><tr><td>2</td><td>2</td><td>2016</td><td>0</td><td>10</td><td>78</td><td>12</td><td>64</td><td>26</td></tr><tr><td>3</td><td>2</td><td>2016</td><td>0</td><td>10</td><td>78</td><td>12</td><td>64</td><td>26</td></tr><tr><td>4</td><td>2</td><td>2016</td><td>0</td><td>10</td><td>78</td><td>12</td><td>64</td><td>26</td></tr><tr><td>5</td><td>6</td><td>2016</td><td>0</td><td>10</td><td>78</td><td>12</td><td>64</td><td>26</td></tr><tr><td>6</td><td>0</td><td>2016</td><td>0</td><td>10</td><td>78</td><td>12</td><td>64</td><td>26</td></tr><tr><td>1</td><td>0</td><td>2016</td><td>1</td><td>10</td><td>78</td><td>2</td><td>64</td><td>28</td></tr><tr><td>2</td><td>0</td><td>2016</td><td>1</td><td>10</td><td>78</td><td>2</td><td>64</td><td>28</td></tr><tr><td>3</td><td>2</td><td>2016</td><td>1</td><td>10</td><td>78</td><td>2</td><td>64</td><td>28</td></tr><tr><td>4</td><td>0</td><td>2016</td><td>1</td><td>10</td><td>78</td><td>2</td><td>64</td><td>28</td></tr><tr><td>5</td><td>0</td><td>2016</td><td>1</td><td>10</td><td>78</td><td>2</td><td>64</td><td>28</td></tr><tr><td>6</td><td>0</td><td>2016</td><td>1</td><td>10</td><td>78</td><td>2</td><td>64</td><td>28</td></tr><tr><td>1</td><td>0</td><td>2016</td><td>2</td><td>10</td><td>78</td><td>12</td><td>64</td><td>40</td></tr><tr><td>2</td><td>6</td><td>2016</td><td>2</td><td>10</td><td>78</td><td>12</td><td>64</td><td>40</td></tr><tr><td>3</td><td>0</td><td>2016</td><td>2</td><td>10</td><td>78</td><td>12</td><td>64</td><td>40</td></tr><tr><td>4</td><td>4</td><td>2016</td><td>2</td><td>10</td><td>78</td><td>12</td><td>64</td><td>40</td></tr><tr><td>5</td><td>0</td><td>2016</td><td>2</td><td>10</td><td>78</td><td>12</td><td>64</td><td>40</td></tr><tr><td>6</td><td>2</td><td>2016</td><td>2</td><td>10</td><td>78</td><td>12</td><td>64</td><td>40</td></tr><tr><td>1</td><td>0</td><td>2016</td><td>3</td><td>10</td><td>78</td><td>4</td><td>64</td><td>44</td></tr><tr><td>2</td><td>0</td><td>2016</td><td>3</td><td>10</td><td>78</td><td>4</td><td>64</td><td>44</td></tr><tr><td>3</td><td>0</td><td>2016</td><td>3</td><td>10</td><td>78</td><td>4</td><td>64</td><td>44</td></tr><tr><td>4</td><td>4</td><td>2016</td><td>3</td><td>10</td><td>78</td><td>4</td><td>64</td><td>44</td></tr><tr><td>5</td><td>0</td><td>2016</td><td>3</td><td>10</td><td>78</td><td>4</td><td>64</td><td>44</td></tr><tr><td>6</td><td>0</td><td>2016</td><td>3</td><td>10</td><td>78</td><td>4</td><td>64</td><td>44</td></tr><tr><td>1</td><td>0</td><td>2016</td><td>4</td><td>10</td><td>78</td><td>8</td><td>64</td><td>52</td></tr><tr><td>2</td><td>0</td><td>2016</td><td>4</td><td>10</td><td>78</td><td>8</td><td>64</td><td>52</td></tr><tr><td>3</td><td>2</td><td>2016</td><td>4</td><td>10</td><td>78</td><td>8</td><td>64</td><td>52</td></tr><tr><td>4</td><td>4</td><td>2016</td><td>4</td><td>10</td><td>78</td><td>8</td><td>64</td><td>52</td></tr><tr><td>5</td><td>0</td><td>2016</td><td>4</td><td>10</td><td>78</td><td>8</td><td>64</td><td>52</td></tr><tr><td>6</td><td>2</td><td>2016</td><td>4</td><td>10</td><td>78</td><td>8</td><td>64</td><td>52</td></tr><tr><td>1</td><td>4</td><td>2016</td><td>5</td><td>10</td><td>78</td><td>12</td><td>64</td><td>64</td></tr><tr><td>2</td><td>0</td><td>2016</td><td>5</td><td>10</td><td>78</td><td>12</td><td>64</td><td>64</td></tr><tr><td>3</td><td>0</td><td>2016</td><td>5</td><td>10</td><td>78</td><td>12</td><td>64</td><td>64</td></tr><tr><td>4</td><td>8</td><td>2016</td><td>5</td><td>10</td><td>78</td><td>12</td><td>64</td><td>64</td></tr><tr><td>5</td><td>0</td><td>2016</td><td>5</td><td>10</td><td>78</td><td>12</td><td>64</td><td>64</td></tr><tr><td>6</td><td>0</td><td>2016</td><td>5</td><td>10</td><td>78</td><td>12</td><td>64</td><td>64</td></tr><tr><td>1</td><td>0</td><td>2016</td><td>6</td><td>10</td><td>78</td><td>14</td><td>64</td><td>78</td></tr><tr><td>2</td><td>0</td><td>2016</td><td>6</td><td>10</td><td>78</td><td>14</td><td>64</td><td>78</td></tr><tr><td>3</td><td>0</td><td>2016</td><td>6</td><td>10</td><td>78</td><td>14</td><td>64</td><td>78</td></tr><tr><td>4</td><td>6</td><td>2016</td><td>6</td><td>10</td><td>78</td><td>14</td><td>64</td><td>78</td></tr><tr><td>5</td><td>2</td><td>2016</td><td>6</td><td>10</td><td>78</td><td>14</td><td>64</td><td>78</td></tr><tr><td>6</td><td>6</td><td>2016</td><td>6</td><td>10</td><td>78</td><td>14</td><td>64</td><td>78</td></tr><tr><td>1</td><td>0</td><td>2020</td><td>0</td><td>8</td><td>20</td><td>8</td><td>20</td><td>8</td></tr><tr><td>2</td><td>2</td><td>2020</td><td>0</td><td>8</td><td>20</td><td>8</td><td>20</td><td>8</td></tr><tr><td>3</td><td>0</td><td>2020</td><td>0</td><td>8</td><td>20</td><td>8</td><td>20</td><td>8</td></tr><tr><td>4</td><td>0</td><td>2020</td><td>0</td><td>8</td><td>20</td><td>8</td><td>20</td><td>8</td></tr><tr><td>5</td><td>0</td><td>2020</td><td>0</td><td>8</td><td>20</td><td>8</td><td>20</td><td>8</td></tr><tr><td>6</td><td>2</td><td>2020</td><td>0</td><td>8</td><td>20</td><td>8</td><td>20</td><td>8</td></tr><tr><td>3</td><td>4</td><td>2020</td><td>0</td><td>8</td><td>20</td><td>8</td><td>20</td><td>8</td></tr><tr><td>1</td><td>0</td><td>2020</td><td>1</td><td>8</td><td>20</td><td>0</td><td>20</td><td>8</td></tr><tr><td>2</td><td>0</td><td>2020</td><td>1</td><td>8</td><td>20</td><td>0</td><td>20</td><td>8</td></tr><tr><td>3</td><td>0</td><td>2020</td><td>1</td><td>8</td><td>20</td><td>0</td><td>20</td><td>8</td></tr><tr><td>4</td><td>0</td><td>2020</td><td>1</td><td>8</td><td>20</td><td>0</td><td>20</td><td>8</td></tr><tr><td>5</td><td>0</td><td>2020</td><td>1</td><td>8</td><td>20</td><td>0</td><td>20</td><td>8</td></tr><tr><td>6</td><td>0</td><td>2020</td><td>1</td><td>8</td><td>20</td><td>0</td><td>20</td><td>8</td></tr><tr><td>1</td><td>0</td><td>2020</td><td>2</td><td>8</td><td>20</td><td>0</td><td>20</td><td>8</td></tr><tr><td>2</td><td>0</td><td>2020</td><td>2</td><td>8</td><td>20</td><td>0</td><td>20</td><td>8</td></tr><tr><td>3</td><td>0</td><td>2020</td><td>2</td><td>8</td><td>20</td><td>0</td><td>20</td><td>8</td></tr><tr><td>4</td><td>0</td><td>2020</td><td>2</td><td>8</td><td>20</td><td>0</td><td>20</td><td>8</td></tr><tr><td>5</td><td>0</td><td>2020</td><td>2</td><td>8</td><td>20</td><td>0</td><td>20</td><td>8</td></tr><tr><td>6</td><td>0</td><td>2020</td><td>2</td><td>8</td><td>20</td><td>0</td><td>20</td><td>8</td></tr><tr><td>1</td><td>0</td><td>2020</td><td>3</td><td>8</td><td>20</td><td>0</td><td>20</td><td>8</td></tr><tr><td>2</td><td>0</td><td>2020</td><td>3</td><td>8</td><td>20</td><td>0</td><td>20</td><td>8</td></tr><tr><td>3</td><td>0</td><td>2020</td><td>3</td><td>8</td><td>20</td><td>0</td><td>20</td><td>8</td></tr><tr><td>4</td><td>0</td><td>2020</td><td>3</td><td>8</td><td>20</td><td>0</td><td>20</td><td>8</td></tr><tr><td>5</td><td>0</td><td>2020</td><td>3</td><td>8</td><td>20</td><td>0</td><td>20</td><td>8</td></tr><tr><td>6</td><td>0</td><td>2020</td><td>3</td><td>8</td><td>20</td><td>0</td><td>20</td><td>8</td></tr><tr><td>1</td><td>0</td><td>2020</td><td>4</td><td>8</td><td>20</td><td>2</td><td>20</td><td>10</td></tr><tr><td>2</td><td>0</td><td>2020</td><td>4</td><td>8</td><td>20</td><td>2</td><td>20</td><td>10</td></tr><tr><td>3</td><td>2</td><td>2020</td><td>4</td><td>8</td><td>20</td><td>2</td><td>20</td><td>10</td></tr><tr><td>4</td><td>0</td><td>2020</td><td>4</td><td>8</td><td>20</td><td>2</td><td>20</td><td>10</td></tr><tr><td>5</td><td>0</td><td>2020</td><td>4</td><td>8</td><td>20</td><td>2</td><td>20</td><td>10</td></tr><tr><td>6</td><td>0</td><td>2020</td><td>4</td><td>8</td><td>20</td><td>2</td><td>20</td><td>10</td></tr><tr><td>5</td><td>2</td><td>2020</td><td>5</td><td>8</td><td>20</td><td>6</td><td>20</td><td>16</td></tr><tr><td>6</td><td>4</td><td>2020</td><td>5</td><td>8</td><td>20</td><td>6</td><td>20</td><td>16</td></tr><tr><td>3</td><td>4</td><td>2020</td><td>6</td><td>8</td><td>20</td><td>4</td><td>20</td><td>20</td></tr></tbody></table></div>"]}}],"execution_count":7},{"cell_type":"code","source":["df.withColumn(\"rownum\", F.row_number().over(w3)).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     62</span>         <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">---&gt; 63</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     64</span>         <span class=\"ansi-green-fg\">except</span> py4j<span class=\"ansi-blue-fg\">.</span>protocol<span class=\"ansi-blue-fg\">.</span>Py4JJavaError <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py</span> in <span class=\"ansi-cyan-fg\">get_return_value</span><span class=\"ansi-blue-fg\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    327</span>                     <span class=\"ansi-blue-fg\">&#34;An error occurred while calling {0}{1}{2}.\\n&#34;</span><span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-fg\">--&gt; 328</span><span class=\"ansi-red-fg\">                     format(target_id, &#34;.&#34;, name), value)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    329</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-red-fg\">Py4JJavaError</span>: An error occurred while calling o1006.withColumn.\n: org.apache.spark.sql.AnalysisException: Window function row_number() requires window to be ordered, please add ORDER BY clause. For example SELECT row_number()(value_expr) OVER (PARTITION BY window_partition ORDER BY window_ordering) from table;\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$class.failAnalysis(CheckAnalysis.scala:46)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.failAnalysis(Analyzer.scala:103)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveWindowOrder$$anonfun$apply$33.applyOrElse(Analyzer.scala:2290)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveWindowOrder$$anonfun$apply$33.applyOrElse(Analyzer.scala:2288)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$2.apply(TreeNode.scala:279)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$2.apply(TreeNode.scala:279)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:76)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:278)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:284)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:284)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$8.apply(TreeNode.scala:353)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:207)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:351)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:284)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsDown$1.apply(QueryPlan.scala:84)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsDown$1.apply(QueryPlan.scala:84)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$3.apply(QueryPlan.scala:106)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$3.apply(QueryPlan.scala:106)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:76)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:105)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:117)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1$2.apply(QueryPlan.scala:122)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.immutable.List.map(List.scala:296)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:122)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$4.apply(QueryPlan.scala:127)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:207)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:127)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsDown(QueryPlan.scala:84)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressions(QueryPlan.scala:75)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveExpressions$1.applyOrElse(AnalysisHelper.scala:129)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveExpressions$1.applyOrElse(AnalysisHelper.scala:128)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsDown$1$$anonfun$2.apply(AnalysisHelper.scala:108)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsDown$1$$anonfun$2.apply(AnalysisHelper.scala:108)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:76)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsDown$1.apply(AnalysisHelper.scala:107)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsDown$1.apply(AnalysisHelper.scala:106)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsDown(AnalysisHelper.scala:106)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsDown(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperators(AnalysisHelper.scala:73)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperators(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveExpressions(AnalysisHelper.scala:128)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveExpressions(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveWindowOrder$.apply(Analyzer.scala:2288)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveWindowOrder$.apply(Analyzer.scala:2287)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:112)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:109)\n\tat scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:124)\n\tat scala.collection.immutable.List.foldLeft(List.scala:84)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:109)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:101)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:101)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:137)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:131)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:103)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$executeAndTrack$1.apply(RuleExecutor.scala:80)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$executeAndTrack$1.apply(RuleExecutor.scala:80)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:88)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:79)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:115)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:114)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:114)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$analyzed$1.apply(QueryExecution.scala:86)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$analyzed$1.apply(QueryExecution.scala:83)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:83)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:83)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:75)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:81)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withPlan(Dataset.scala:3534)\n\tat org.apache.spark.sql.Dataset.select(Dataset.scala:1362)\n\tat org.apache.spark.sql.Dataset.withColumns(Dataset.scala:2327)\n\tat org.apache.spark.sql.Dataset.withColumn(Dataset.scala:2294)\n\tat sun.reflect.GeneratedMethodAccessor387.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\n\n\nDuring handling of the above exception, another exception occurred:\n\n<span class=\"ansi-red-fg\">AnalysisException</span>                         Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3415441722162643&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>df<span class=\"ansi-blue-fg\">.</span>withColumn<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;rownum&#34;</span><span class=\"ansi-blue-fg\">,</span> F<span class=\"ansi-blue-fg\">.</span>row_number<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>over<span class=\"ansi-blue-fg\">(</span>w3<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/dataframe.py</span> in <span class=\"ansi-cyan-fg\">withColumn</span><span class=\"ansi-blue-fg\">(self, colName, col)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   2023</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-intense-fg ansi-bold\">   2024</span>         <span class=\"ansi-green-fg\">assert</span> isinstance<span class=\"ansi-blue-fg\">(</span>col<span class=\"ansi-blue-fg\">,</span> Column<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;col should be Column&#34;</span>\n<span class=\"ansi-green-fg\">-&gt; 2025</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> DataFrame<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jdf<span class=\"ansi-blue-fg\">.</span>withColumn<span class=\"ansi-blue-fg\">(</span>colName<span class=\"ansi-blue-fg\">,</span> col<span class=\"ansi-blue-fg\">.</span>_jc<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>sql_ctx<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   2026</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   2027</span>     <span class=\"ansi-blue-fg\">@</span>ignore_unicode_prefix\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1255</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1256</span>         return_value = get_return_value(\n<span class=\"ansi-green-fg\">-&gt; 1257</span><span class=\"ansi-red-fg\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1258</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1259</span>         <span class=\"ansi-green-fg\">for</span> temp_arg <span class=\"ansi-green-fg\">in</span> temp_args<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     67</span>                                              e.java_exception.getStackTrace()))\n<span class=\"ansi-green-intense-fg ansi-bold\">     68</span>             <span class=\"ansi-green-fg\">if</span> s<span class=\"ansi-blue-fg\">.</span>startswith<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;org.apache.spark.sql.AnalysisException: &#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">---&gt; 69</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">raise</span> AnalysisException<span class=\"ansi-blue-fg\">(</span>s<span class=\"ansi-blue-fg\">.</span>split<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;: &#39;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> stackTrace<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     70</span>             <span class=\"ansi-green-fg\">if</span> s<span class=\"ansi-blue-fg\">.</span>startswith<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;org.apache.spark.sql.catalyst.analysis&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     71</span>                 <span class=\"ansi-green-fg\">raise</span> AnalysisException<span class=\"ansi-blue-fg\">(</span>s<span class=\"ansi-blue-fg\">.</span>split<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;: &#39;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> stackTrace<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">AnalysisException</span>: &#39;Window function row_number() requires window to be ordered, please add ORDER BY clause. For example SELECT row_number()(value_expr) OVER (PARTITION BY window_partition ORDER BY window_ordering) from table;&#39;</div>"]}}],"execution_count":8},{"cell_type":"code","source":["list=[['8A',1,'CPH','GDN'],                \n      ['8A',1,'GDN','CPH'],                 \n      ['8A',2,'GDN','CPH'],               \n      ['8A',2,'CPH','GDN'],                \n      ['8A',3,'CPH','GDN'],                 \n      ['8A',3,'GDN','CPH'],                 \n      ['8A',4,'CPH','GDN'],                  \n      ['8A',4,'GDN','CPH'],\n      ['8A',5,'GDN','GDN'],\n      ['8A',5,'CPH','GDN']] \ndf=spark.createDataFrame(list,['id','val_no','stn_fr_cd','stn_to_cd'])\ndf.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+------+---------+---------+\n id|val_no|stn_fr_cd|stn_to_cd|\n+---+------+---------+---------+\n 8A|     1|      CPH|      GDN|\n 8A|     1|      GDN|      CPH|\n 8A|     2|      GDN|      CPH|\n 8A|     2|      CPH|      GDN|\n 8A|     3|      CPH|      GDN|\n 8A|     3|      GDN|      CPH|\n 8A|     4|      CPH|      GDN|\n 8A|     4|      GDN|      CPH|\n 8A|     5|      GDN|      GDN|\n 8A|     5|      CPH|      GDN|\n+---+------+---------+---------+\n\n</div>"]}}],"execution_count":9},{"cell_type":"code","source":["from pyspark.sql import functions as F\nfrom pyspark.sql.window import Window\nw=Window().partitionBy(\"id\",\"val_no\").orderBy(\"val_no\")\n\ndf.withColumn(\"fr\", F.lead(\"stn_fr_cd\").over(w))\\\n  .withColumn(\"to\", F.lead(\"stn_to_cd\").over(w))\\\n  .withColumn(\"check\", F.when((F.col(\"stn_fr_cd\")==F.col(\"to\"))&(F.col(\"stn_to_cd\")==F.col(\"fr\")),F.lit(1)).otherwise(F.lit(0))).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+------+---------+---------+----+----+-----+\n id|val_no|stn_fr_cd|stn_to_cd|  fr|  to|check|\n+---+------+---------+---------+----+----+-----+\n 8A|     2|      GDN|      CPH| CPH| GDN|    1|\n 8A|     2|      CPH|      GDN|null|null|    0|\n 8A|     3|      CPH|      GDN| GDN| CPH|    1|\n 8A|     3|      GDN|      CPH|null|null|    0|\n 8A|     4|      CPH|      GDN| GDN| CPH|    1|\n 8A|     4|      GDN|      CPH|null|null|    0|\n 8A|     1|      CPH|      GDN| GDN| CPH|    1|\n 8A|     1|      GDN|      CPH|null|null|    0|\n 8A|     5|      GDN|      GDN| CPH| GDN|    0|\n 8A|     5|      CPH|      GDN|null|null|    0|\n+---+------+---------+---------+----+----+-----+\n\n</div>"]}}],"execution_count":10},{"cell_type":"code","source":["from pyspark.sql import functions as F\nfrom pyspark.sql.types import *\nfrom pyspark.sql.window import Window"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":11},{"cell_type":"code","source":["list= [['A' , 'B' , 0.77],\n       ['B' , 'C' , 0.56],\n       ['C' , 'A' , 0.88],\n       ['D' , 'E', 0.9],\n       ['E','F',0.71],\n       ['F','D',0.91]]\n\ndf=spark.createDataFrame(list, ['col1','col2','dist'])\ndf.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----+----+----+\ncol1|col2|dist|\n+----+----+----+\n   A|   B|0.77|\n   B|   C|0.56|\n   C|   A|0.88|\n   D|   E| 0.9|\n   E|   F|0.71|\n   F|   D|0.91|\n+----+----+----+\n\n</div>"]}}],"execution_count":12},{"cell_type":"code","source":["df1=df.groupBy(\"col1\").pivot(\"col2\").agg(F.first(\"dist\")).orderBy(\"col1\")\ndf2=df.groupBy(F.col(\"col2\").alias(\"col1\")).pivot(\"col1\").agg(F.first(\"dist\")).orderBy(\"col1\")\ndf3=df1.union(df2)\ndf3.groupBy(\"col1\")\\\n.agg(*(F.first(x,True).alias(x) for x in df3.columns if x != 'col1'))\\\n.fillna(0)\\\n.orderBy(\"col1\")\\\n.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----+----+----+----+----+----+----+\ncol1|   A|   B|   C|   D|   E|   F|\n+----+----+----+----+----+----+----+\n   A| 0.0|0.77|0.88| 0.0| 0.0| 0.0|\n   B|0.77| 0.0|0.56| 0.0| 0.0| 0.0|\n   C|0.88|0.56| 0.0| 0.0| 0.0| 0.0|\n   D| 0.0| 0.0| 0.0| 0.0| 0.9|0.91|\n   E| 0.0| 0.0| 0.0| 0.9| 0.0|0.71|\n   F| 0.0| 0.0| 0.0|0.91|0.71| 0.0|\n+----+----+----+----+----+----+----+\n\n</div>"]}}],"execution_count":13},{"cell_type":"code","source":["   A        B      C\nA   0       0.77    0.88\n\nB   0.77     0      0.56\n\nC   0.88    0.56    0"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["from pyspark.sql import functions as F\nfrom pyspark.sql.window import Window\nfrom pyspark.sql.types import *\n\nlist=[[1,'2019-01-09',56],\n      [1,'2019-02-09',14],\n      [1,'2019-02-13',48],\n      [1,'2019-03-19',0],\n      [1,'2019-04-08',21],\n      [1,'2019-04-08',4],\n      [2,'2019-08-15',44],\n      [2,'2019-08-25',78],\n      [2,'2019-09-09',15],\n      [2,'2019-10-09',19],\n      [1,'2018-01-03',56],\n      [1,'2018-01-09',25],\n      [1,'2018-02-01',34],\n      [1,'2018-04-09',39],\n      [1,'2018-08-12',14],\n      [1,'2018-09-14',11]]\n\ndf=spark.createDataFrame(list,['product_id','sale_date','sale'])\ndf.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+----------+----+\nproduct_id| sale_date|sale|\n+----------+----------+----+\n         1|2019-01-09|  56|\n         1|2019-02-09|  14|\n         1|2019-02-13|  48|\n         1|2019-03-19|   0|\n         1|2019-04-08|  21|\n         1|2019-04-08|   4|\n         2|2019-08-15|  44|\n         2|2019-08-25|  78|\n         2|2019-09-09|  15|\n         2|2019-10-09|  19|\n         1|2018-01-03|  56|\n         1|2018-01-09|  25|\n         1|2018-02-01|  34|\n         1|2018-04-09|  39|\n         1|2018-08-12|  14|\n         1|2018-09-14|  11|\n+----------+----------+----+\n\n</div>"]}}],"execution_count":15},{"cell_type":"code","source":["df1=df.withColumn(\"sale_date\", F.to_date(\"sale_date\", \"yyyy-MM-dd\"))\\\n      .withColumn(\"Year\", F.year(\"sale_date\"))\\\n      .withColumn(\"Month\", F.month(\"sale_date\"))\\\n      .withColumn(\"Day\",F.dayofmonth(\"sale_date\"))\n\nw=Window().partitionBy(F.col(\"product_id\"),F.col(\"Year\")).orderBy(F.col(\"Month\"),F.col(\"Day\"))\\\n          .rowsBetween(Window.unboundedPreceding,Window.currentRow)\n\n\nw3=Window().partitionBy(\"product_id\",\"Year\",\"Month\",\"Day\")\nw4=Window().partitionBy(\"product_id\",\"Year\",\"Month\",\"Day\").orderBy(\"Day\")\nw5=Window().partitionBy(\"product_id\",\"Year\").orderBy(\"Month\",\"Day\")\n\ndf1.withColumn(\"YTD_METHOD1\", F.sum(\"sale\").over(w))\\\n   .withColumn(\"total_sales_by_day\", F.sum(\"sale\").over(w3))\\\n   .withColumn(\"rownum\", F.row_number().over(w4))\\\n   .withColumn(\"newday\", F.when(F.col(\"rownum\")!=1, F.lit(0)).otherwise(F.col(\"total_sales_by_day\")))\\\n   .withColumn(\"YTD_METHOD2\", F.sum(\"newday\").over(w5))\\\n   .select(\"product_id\",\"sale_date\",\"sale\",\"total_sales_by_day\",\"rownum\",\"newday\",\"YTD_METHOD2\")\\\n   .show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+----------+----+------------------+------+------+-----------+\nproduct_id| sale_date|sale|total_sales_by_day|rownum|newday|YTD_METHOD2|\n+----------+----------+----+------------------+------+------+-----------+\n         1|2019-01-09|  56|                56|     1|    56|         56|\n         1|2019-02-09|  14|                14|     1|    14|         70|\n         1|2019-02-13|  48|                48|     1|    48|        118|\n         1|2019-03-19|   0|                 0|     1|     0|        118|\n         1|2019-04-08|  21|                25|     1|    25|        143|\n         1|2019-04-08|   4|                25|     2|     0|        143|\n         1|2018-01-03|  56|                56|     1|    56|         56|\n         1|2018-01-09|  25|                25|     1|    25|         81|\n         1|2018-02-01|  34|                34|     1|    34|        115|\n         1|2018-04-09|  39|                39|     1|    39|        154|\n         1|2018-08-12|  14|                14|     1|    14|        168|\n         1|2018-09-14|  11|                11|     1|    11|        179|\n         2|2019-08-15|  44|                44|     1|    44|         44|\n         2|2019-08-25|  78|                78|     1|    78|        122|\n         2|2019-09-09|  15|                15|     1|    15|        137|\n         2|2019-10-09|  19|                19|     1|    19|        156|\n+----------+----------+----+------------------+------+------+-----------+\n\n</div>"]}}],"execution_count":16},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":17}],"metadata":{"name":"stackhelp36","notebookId":3617736183930611},"nbformat":4,"nbformat_minor":0}
