{"cells":[{"cell_type":"code","source":["from pyspark.sql import functions as F\nfrom pyspark.sql.window import Window\nfrom pyspark.sql.types import *\nfrom pyspark.storagelevel import StorageLevel"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["list=[['user1',   '12/1/19 8:00'],\n      ['user1' ,  '12/1/19 10:00'],\n      ['user1'  , '12/1/19 23:00'],\n      ['user1'   ,'12/2/19 7:00'],\n      ['user1'   ,'12/2/19 8:00'],\n      ['user1'   ,'12/2/19 10:00'],\n      ['user1'   ,'12/3/19 23:00'],\n      ['user1'   ,'12/4/19 7:00'],\n      ['user2'   ,'12/4/19 8:00'],\n      ['user2'   ,'12/5/19 5:00'],\n      ['user2'   ,'12/6/19 0:00']]\ndf=spark.createDataFrame(list,['user','login'])\ndf.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+-------------+\n user|        login|\n+-----+-------------+\nuser1| 12/1/19 8:00|\nuser1|12/1/19 10:00|\nuser1|12/1/19 23:00|\nuser1| 12/2/19 7:00|\nuser1| 12/2/19 8:00|\nuser1|12/2/19 10:00|\nuser1|12/3/19 23:00|\nuser1| 12/4/19 7:00|\nuser2| 12/4/19 8:00|\nuser2| 12/5/19 5:00|\nuser2| 12/6/19 0:00|\n+-----+-------------+\n\n</div>"]}}],"execution_count":2},{"cell_type":"code","source":["from pyspark.sql import functions as F\nfrom pyspark.sql.window import Window\n\nw=Window().partitionBy(\"user\").orderBy(\"login\").rowsBetween(Window.unboundedPreceding,Window.unboundedFollowing)\nw2=Window().partitionBy(\"user\", \"index\").orderBy(\"login\")\ndf1=df.withColumn(\"login\", F.to_timestamp(\"login\",\"MM/dd/yy HH:mm\"))\ndf1.withColumn(\"firstlogin\", F.first(F.col(\"login\")).over(w))\\\n  .withColumn(\"index\", F.when(((unix_timestamp(col(\"login\")) - unix_timestamp(col(\"firstLogin\"))) / 86400) == 1, F.lit(0)).otherwise(((unix_timestamp(col(\"login\")) - unix_timestamp(col(\"firstLogin\"))) / 86400).cast(\"int\")))\\\n  .withColumn(\"Duplicate\", when(row_number().over(w2) == 1, lit(\"N\")).otherwise(lit(\"Y\"))) \\\n   .orderBy(\"user\", \"login\") \\\n   .show()\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+-------------------+-------------------+-----+---------+\n user|              login|         firstlogin|index|Duplicate|\n+-----+-------------------+-------------------+-----+---------+\nuser1|2019-12-01 08:00:00|2019-12-01 08:00:00|    0|        N|\nuser1|2019-12-01 10:00:00|2019-12-01 08:00:00|    0|        Y|\nuser1|2019-12-01 23:00:00|2019-12-01 08:00:00|    0|        Y|\nuser1|2019-12-02 07:00:00|2019-12-01 08:00:00|    0|        Y|\nuser1|2019-12-02 08:00:00|2019-12-01 08:00:00|    0|        Y|\nuser1|2019-12-02 10:00:00|2019-12-01 08:00:00|    1|        N|\nuser1|2019-12-03 23:00:00|2019-12-01 08:00:00|    2|        N|\nuser1|2019-12-04 07:00:00|2019-12-01 08:00:00|    2|        Y|\nuser2|2019-12-04 08:00:00|2019-12-04 08:00:00|    0|        N|\nuser2|2019-12-05 05:00:00|2019-12-04 08:00:00|    0|        Y|\nuser2|2019-12-06 00:00:00|2019-12-04 08:00:00|    1|        N|\n+-----+-------------------+-------------------+-----+---------+\n\n</div>"]}}],"execution_count":3},{"cell_type":"code","source":["((unix_timestamp(col(\"login\")) - unix_timestamp(col(\"firstLogin\"))) / 86400).cast(\"int\"))"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["from pyspark.sql.functions import col, lag, unix_timestamp, to_timestamp, lit, when, row_number, first\nfrom pyspark.sql import Window\n\nw = Window.partitionBy(\"user\", \"index\").orderBy(\"login\")\ndf2 = df.withColumn(\"login\", to_timestamp(col(\"login\"), \"MM/dd/yy HH:mm\"))\n\ndf2.join(df2.groupBy(\"user\").agg(first(\"login\").alias(\"firstLogin\")), \"user\", \"left\") \\\n   .withColumn(\"index\", F.when(((unix_timestamp(col(\"login\")) - unix_timestamp(col(\"firstLogin\"))) / 86400) == 1, F.lit(0)).otherwise(((unix_timestamp(col(\"login\")) - unix_timestamp(col(\"firstLogin\"))) / 86400).cast(\"int\"))) \\\n   .withColumn(\"Duplicate\", when(row_number().over(w) == 1, lit(\"N\")).otherwise(lit(\"Y\"))) \\\n   .orderBy(\"user\", \"login\") \\\n   .show(20)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+-------------------+-------------------+-----+---------+\n user|              login|         firstLogin|index|Duplicate|\n+-----+-------------------+-------------------+-----+---------+\nuser1|2019-12-01 08:00:00|2019-12-01 08:00:00|    0|        N|\nuser1|2019-12-01 10:00:00|2019-12-01 08:00:00|    0|        Y|\nuser1|2019-12-01 23:00:00|2019-12-01 08:00:00|    0|        Y|\nuser1|2019-12-02 07:00:00|2019-12-01 08:00:00|    0|        Y|\nuser1|2019-12-02 08:00:00|2019-12-01 08:00:00|    0|        Y|\nuser1|2019-12-02 10:00:00|2019-12-01 08:00:00|    1|        N|\nuser1|2019-12-03 23:00:00|2019-12-01 08:00:00|    2|        N|\nuser1|2019-12-04 07:00:00|2019-12-01 08:00:00|    2|        Y|\nuser2|2019-12-04 08:00:00|2019-12-04 08:00:00|    0|        N|\nuser2|2019-12-05 05:00:00|2019-12-04 08:00:00|    0|        Y|\nuser2|2019-12-06 00:00:00|2019-12-04 08:00:00|    1|        N|\n+-----+-------------------+-------------------+-----+---------+\n\n</div>"]}}],"execution_count":5},{"cell_type":"code","source":["from pyspark.sql import functions as F\nfrom pyspark.sql.window import Window"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["list=[[ 'a1' ,     'b1'  ,    'c1'   ,   'd1'],\n     ['a1'  ,   'b2'    ,  'c1'      ,'d1'],\n     ['a1'   ,   'b3'   ,   'c1'     , 'd1'],\n     ['a1'  ,    'b4'   ,   'c1'     , 'd2'],\n     ['a1'   ,   'b5'    ,  'c2'     , 'd2'],\n     ['a1'   ,   'b6'    ,  'c2'     , 'd2'],\n     ['a1'  ,    'b7'    ,  'c1'     , 'd3'],\n     ['a1'  ,    'b8'    , 'c2'      ,'d3'],\n     ['a1'  ,    'b9'    ,  'c3'     , 'd3'],\n     ['a1'  ,    'b10'   ,  'c1'     , 'd2'],\n     [ 'a1'  ,   'b11'   ,  'c2'     , 'd3'],\n     ['a2'  ,    'b12'   ,  'c1'     , 'd1'],\n     ['a3'   ,   'b13'   ,  'c1'     , 'd1']]\n\ndf=spark.createDataFrame(list,['col_1','col_2','col_3','col_4'])\n\ndf.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+-----+-----+-----+\ncol_1|col_2|col_3|col_4|\n+-----+-----+-----+-----+\n   a1|   b1|   c1|   d1|\n   a1|   b2|   c1|   d1|\n   a1|   b3|   c1|   d1|\n   a1|   b4|   c1|   d2|\n   a1|   b5|   c2|   d2|\n   a1|   b6|   c2|   d2|\n   a1|   b7|   c1|   d3|\n   a1|   b8|   c2|   d3|\n   a1|   b9|   c3|   d3|\n   a1|  b10|   c1|   d2|\n   a1|  b11|   c2|   d3|\n   a2|  b12|   c1|   d1|\n   a3|  b13|   c1|   d1|\n+-----+-----+-----+-----+\n\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":["w=Window().partitionBy(\"col_3\",\"col_4\")\nw2=Window().partitionBy()\n\ndf.withColumn(\"count\", F.count(\"*\").over(w)).withColumn(\"max\", F.max(\"count\").over(w2)).filter(\"count=max\")\\\n  .groupBy(F.col(\"col_1\")).agg(*(F.first(x).alias(x) for x in df.columns if x!= 'col_1' and x!='count')).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+-----+-----+-----+\ncol_1|col_2|col_3|col_4|\n+-----+-----+-----+-----+\n   a1|   b1|   c1|   d1|\n   a2|  b12|   c1|   d1|\n   a3|  b13|   c1|   d1|\n+-----+-----+-----+-----+\n\n</div>"]}}],"execution_count":8},{"cell_type":"code","source":["w=Window().partitionBy(\"col_3\",\"col_4\")\n\n\ndf.withColumn(\"count\", F.count(\"*\").over(w))\\\n  .groupBy(F.col(\"col_1\")).agg(F.max(\"count\"),*(F.first(x).alias(x) for x in df.columns if x!= 'col_1' and x!='count')).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+----------+-----+-----+-----+\ncol_1|max(count)|col_2|col_3|col_4|\n+-----+----------+-----+-----+-----+\n   a3|         5|  b13|   c1|   d1|\n   a2|         5|  b12|   c1|   d1|\n   a1|         5|   b7|   c1|   d3|\n+-----+----------+-----+-----+-----+\n\n</div>"]}}],"execution_count":9},{"cell_type":"code","source":[".groupBy(F.col(\"col_1\")).agg(F.first(*(x for x in df.columns if x!=col_1))).show()"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["from pyspark.sql import functions as F\nfrom pyspark.sql.window import Window\nfrom pyspark.sql.types import *\nfrom pyspark.storagelevel import StorageLevel"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":11},{"cell_type":"code","source":["list1= [[1,'Michael' ,'Jackson', 'mj@yahoo.com'],\n       [2,'Roger','Moore','rm@rocketmail.com'],\n       [3,'Angela','Merkel','am@dw.de']]\n\n\n\n\nlist2= [[1,'Michael' ,'Jordan', 'mj@yahoo.com'],\n       [2,'Gordon','Moore','rm@rocketmail.com'],\n       [3,'Angela','Merkle','am@dw.com']]\n\n\ndf1= spark.createDataFrame(list1,['id'  ,'fname',   'lname',   'email'])\ndf2= spark.createDataFrame(list2,['id'  ,'fname','lname' ,'email'])\n\ndf1.show()\ndf2.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+-------+-------+-----------------+\n id|  fname|  lname|            email|\n+---+-------+-------+-----------------+\n  1|Michael|Jackson|     mj@yahoo.com|\n  2|  Roger|  Moore|rm@rocketmail.com|\n  3| Angela| Merkel|         am@dw.de|\n+---+-------+-------+-----------------+\n\n+---+-------+------+-----------------+\n id|  fname| lname|            email|\n+---+-------+------+-----------------+\n  1|Michael|Jordan|     mj@yahoo.com|\n  2| Gordon| Moore|rm@rocketmail.com|\n  3| Angela|Merkle|        am@dw.com|\n+---+-------+------+-----------------+\n\n</div>"]}}],"execution_count":12},{"cell_type":"code","source":["df3=df1.join(df2.select(F.col(\"id\"),F.col(\"fname\").alias(\"fname1\"),F.col(\"lname\").alias(\"lname1\"),F.col(\"email\").alias(\"email1\")),['id'])\ncollected=df3.withColumn(\"fname1\", F.when(F.col(\"fname1\")!=F.col(\"fname\"),F.lit(\"fname\")).otherwise(F.lit(None)))\\\n  .withColumn(\"lname1\", F.when(F.col(\"lname1\")!=F.col(\"lname\"),F.lit(\"lname\")).otherwise(F.lit(None)))\\\n  .withColumn(\"email1\", F.when(F.col(\"email1\")!=F.col(\"email\"),F.lit(\"email\")).otherwise(F.lit(None)))\\\n  .withColumn(\"different\", F.array(*(x for x in ['fname1','lname1','email1']))).select(\"id\",\"different\")\\\n  .withColumn(\"different\", F.expr(\"\"\"filter(different, x-> x is  not null)\"\"\")).orderBy(\"id\").collect()\ndic={}\nfor i in collected:\n  dic.update({i[0] : i[1]})\ndic"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[48]: {1: [&#39;lname&#39;], 2: [&#39;fname&#39;], 3: [&#39;lname&#39;, &#39;email&#39;]}</div>"]}}],"execution_count":13},{"cell_type":"code","source":["df3=df1.join(df2.select(F.col(\"id\"),F.col(\"fname\").alias(\"fname1\"),F.col(\"lname\").alias(\"lname1\"),F.col(\"email\").alias(\"email1\")),['id'])\ncollected=df3.withColumn(\"fname1\", F.when(F.col(\"fname1\")!=F.col(\"fname\"),F.lit(\"fname\")).otherwise(F.lit(None)))\\\n  .withColumn(\"lname1\", F.when(F.col(\"lname1\")!=F.col(\"lname\"),F.lit(\"lname\")).otherwise(F.lit(None)))\\\n  .withColumn(\"email1\", F.when(F.col(\"email1\")!=F.col(\"email\"),F.lit(\"email\")).otherwise(F.lit(None)))\\\n  .withColumn(\"different\", F.array(*(x for x in ['fname1','lname1','email1']))).select(\"id\",\"different\")\\\n  .withColumn(\"different\", F.expr(\"\"\"filter(different, x-> x is  not null)\"\"\")).orderBy(\"id\").toJSON().collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":14},{"cell_type":"code","source":["collected"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[50]: [&#39;{&#34;id&#34;:1,&#34;different&#34;:[&#34;lname&#34;]}&#39;,\n &#39;{&#34;id&#34;:2,&#34;different&#34;:[&#34;fname&#34;]}&#39;,\n &#39;{&#34;id&#34;:3,&#34;different&#34;:[&#34;lname&#34;,&#34;email&#34;]}&#39;]</div>"]}}],"execution_count":15},{"cell_type":"code","source":["dic={}\nfor i in collected:\n  dic.update({i[0] : i[1]})"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":16},{"cell_type":"code","source":[""],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">ValueError</span>                                Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3186152684721686&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> dict<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">{</span><span class=\"ansi-blue-fg\">}</span>\n<span class=\"ansi-green-fg\">----&gt; 2</span><span class=\"ansi-red-fg\"> </span>dic<span class=\"ansi-blue-fg\">.</span>update<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">{</span>i<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">0</span><span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-blue-fg\">:</span> i<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">}</span><span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">for</span> i <span class=\"ansi-green-fg\">in</span> collected<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">ValueError</span>: dictionary update sequence element #0 has length 1; 2 is required</div>"]}}],"execution_count":17},{"cell_type":"code","source":["dic"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[39]: {1: [&#39;lname&#39;], 2: [&#39;fname&#39;], 3: [&#39;lname&#39;, &#39;email&#39;]}</div>"]}}],"execution_count":18},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":19}],"metadata":{"name":"stackhelp39","notebookId":3604619484648080},"nbformat":4,"nbformat_minor":0}
