{"cells":[{"cell_type":"code","source":["from pyspark.sql import functions as F \nfrom pyspark.sql.window import Window\nfrom pyspark.sql.types import *\nfrom pyspark.storagelevel import StorageLevel"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["list=[[\"2015-03-14\"],\n     [\"2015-03-14\"],\n     [\"2015-03-15\"]]\n\ndf=spark.createDataFrame(list,['date'])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["df.filter(\"date>'2015-03-14'\").show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+\n      date|\n+----------+\n2015-03-15|\n+----------+\n\n</div>"]}}],"execution_count":3},{"cell_type":"code","source":["list=[['2020-02-23 11:42:34',38       ,'0000126D',35,'24'],\n['2020-02-24 11:47:34',38,'0000126D',35,'24'],\n['2020-02-24 11:48:34',38,'0000126D',35              ,'23'],        \n['2020-02-24 11:49:34',38       ,'0000126D',35              ,'23'],         \n['2020-02-24 11:50:34',38       ,'0000126D',35              ,'22'],         \n['2020-02-25 11:52:34',38       ,'0000126D',35              ,'22'],        \n['2020-02-25 11:12:35',38       ,'0000126D',35              ,'21'],         \n['2020-02-26 11:34:35',38       ,'0000126D',35              ,'21'],         \n['2020-02-27 11:12:35',38       ,'0000126D',35              ,'2A'],         \n['2020-02-28 11:43:35',38       ,'0000126D',35              ,'2A'],        \n['2020-03-01 11:23:35',38       ,'0000126D',35              ,'24'],       \n['2020-03-02 11:10:35',38       ,'0000126D',35              ,'24'],        \n['2020-03-03 11:07:35',38       ,'0000126D',35              ,'23'],        \n['2020-03-04 11:31:35',38       ,'0000126D',35              ,'23'],        \n['2020-03-05 11:07:35',38       ,'0000126D',35              ,'22'],        \n['2020-03-06 11:17:35',38       ,'0000126D',35              ,'22'],        \n['2020-03-07 11:15:47',38       ,'0000126D',35              ,'21'],        \n['2020-03-08 11:34:09',38       ,'0000126D',35              ,'21'],        \n['2020-03-07 11:15:47',38       ,'0000126D',35              ,'20'],        \n['2020-03-08 11:34:09',38       ,'0000126D',35              ,'20'],        \n['2020-03-07 11:15:47',38       ,'0000126D',35              ,'2A'],        \n['2020-03-08 11:34:09',38       ,'0000126D',35              ,'2A']] \n\ndf=spark.createDataFrame(list,['DateTime','uid','sensorid','code','result'])\n\ndf.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------------------+---+--------+----+------+\n           DateTime|uid|sensorid|code|result|\n+-------------------+---+--------+----+------+\n2020-02-23 11:42:34| 38|0000126D|  35|    24|\n2020-02-24 11:47:34| 38|0000126D|  35|    24|\n2020-02-24 11:48:34| 38|0000126D|  35|    23|\n2020-02-24 11:49:34| 38|0000126D|  35|    23|\n2020-02-24 11:50:34| 38|0000126D|  35|    22|\n2020-02-25 11:52:34| 38|0000126D|  35|    22|\n2020-02-25 11:12:35| 38|0000126D|  35|    21|\n2020-02-26 11:34:35| 38|0000126D|  35|    21|\n2020-02-27 11:12:35| 38|0000126D|  35|    2A|\n2020-02-28 11:43:35| 38|0000126D|  35|    2A|\n2020-03-01 11:23:35| 38|0000126D|  35|    24|\n2020-03-02 11:10:35| 38|0000126D|  35|    24|\n2020-03-03 11:07:35| 38|0000126D|  35|    23|\n2020-03-04 11:31:35| 38|0000126D|  35|    23|\n2020-03-05 11:07:35| 38|0000126D|  35|    22|\n2020-03-06 11:17:35| 38|0000126D|  35|    22|\n2020-03-07 11:15:47| 38|0000126D|  35|    21|\n2020-03-08 11:34:09| 38|0000126D|  35|    21|\n2020-03-07 11:15:47| 38|0000126D|  35|    20|\n2020-03-08 11:34:09| 38|0000126D|  35|    20|\n+-------------------+---+--------+----+------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":4},{"cell_type":"code","source":["df.filter(\"DateTime > '2020-03-11 00:00:00'\").show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+---+--------+----+------+\nDateTime|uid|sensorid|code|result|\n+--------+---+--------+----+------+\n+--------+---+--------+----+------+\n\n</div>"]}}],"execution_count":5},{"cell_type":"code","source":["list=[['2020-02-23 11:42:34'       ,'0000111D'        ,'30'],        \n['2020-02-24 11:47:34'       ,'0000111D'              ,'30'],\n['2020-02-24 11:48:34'      ,'0000111D'               ,'29'],       \n['2020-02-24 11:49:34'       ,'0000111D'              ,'29'],        \n['2020-02-24 11:50:34'       ,'0000111D'              ,'28'],       \n['2020-02-25 11:52:34'       ,'0000111D'              ,'28'],       \n['2020-02-25 11:12:35'       ,'0000111D'              ,'27'],       \n['2020-02-26 11:34:35'       ,'0000111D'              ,'27'],       \n['2020-02-27 11:12:35'       ,'0000111D'              ,'2A'],       \n['2020-02-28 11:43:35'       ,'0000111D'              ,'2A'],       \n['2020-03-01 11:23:35'       ,'0000111D'              ,'30'],       \n['2020-03-02 11:10:35'       ,'0000111D'              ,'30'],       \n['2020-03-03 11:07:35'       ,'0000111D'              ,'29'],        \n['2020-03-04 11:31:35'       ,'0000111D'              ,'29'],        \n['2020-03-05 11:07:35'       ,'0000111D'              ,'28'],        \n['2020-03-06 11:17:35'       ,'0000111D'              ,'28'],        \n['2020-03-07 11:15:47'       ,'0000111D'              ,'27'],        \n['2020-03-08 11:34:09'       ,'0000111D'              ,'27'],        \n['2020-03-09 11:15:47'       ,'0000111D'              ,'26'],        \n['2020-03-10 04:12:45'       ,'0000111D'              ,'26'],        \n['2020-03-11 11:15:47'       ,'0000111D'              ,'2A'],        \n['2020-03-12 07:34:09'       ,'0000111D'              ,'2A']]\n\ndf=spark.createDataFrame(list,['DateTime','UID','result'])\ndf.show(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------------------+--------+------+\n           DateTime|     UID|result|\n+-------------------+--------+------+\n2020-02-23 11:42:34|0000111D|    30|\n2020-02-24 11:47:34|0000111D|    30|\n2020-02-24 11:48:34|0000111D|    29|\n2020-02-24 11:49:34|0000111D|    29|\n2020-02-24 11:50:34|0000111D|    28|\n+-------------------+--------+------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":6},{"cell_type":"code","source":["w=Window().partitionBy(\"result\").orderBy(\"DateTime\")\nw1=Window().partitionBy(\"UID\").orderBy(\"DateTime\")\nw2=Window().partitionBy(\"UID\",\"inc_sum\").orderBy(\"DateTime\")\nw3=Window().partitionBy(\"UID\",\"inc_sum\")\ndf.withColumn(\"cor\",F.row_number().over(w))\\\n  .withColumn(\"yo\", F.when((F.col(\"cor\")%2!=0) & (F.col(\"result\")==30),F.lit(1)).otherwise(F.lit(0)))\\\n  .withColumn(\"inc_sum\", F.sum(\"yo\").over(w1))\\\n  .withColumn(\"cor\", F.when((F.col(\"result\")!=30) & (F.col(\"cor\")%2==0), F.lit('change')).otherwise(F.lit('no')))\\\n        .withColumn(\"row_num\", F.row_number().over(w2))\\\n        .withColumn(\"first\", F.min(\"row_num\").over(w3))\\\n        .withColumn(\"max\", F.max(\"row_num\").over(w3)).drop(\"yo\",\"row_num\",\"first\",\"max\")\\\n        .filter(\"row_num=first or row_num=max or cor='change'\")\\\n        .withColumn(\"rownum\", F.concat(F.row_number().over(w2),F.lit(\"_change\")))\\\n        .groupBy(\"UID\").pivot(\"rownum\").agg((F.collect_list(\"DateTime\")))\\\n        .withColumn(\"zip\", F.explode(F.arrays_zip(*['1_change','2_change','3_change','4_change','5_change','6_change'])))\\\n        .select(\"UID\", \"zip.*\").show()\n                                      "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+\n     UID|           1_change|           2_change|           3_change|           4_change|           5_change|           6_change|\n+--------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+\n0000111D|2020-02-23 11:42:34|2020-02-24 11:49:34|2020-02-25 11:52:34|2020-02-26 11:34:35|2020-02-28 11:43:35|2020-03-12 07:34:09|\n0000111D|2020-03-01 11:23:35|2020-03-04 11:31:35|2020-03-06 11:17:35|2020-03-08 11:34:09|2020-03-10 04:12:45|               null|\n+--------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+\n\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":["w=Window().partitionBy(\"result\").orderBy(\"DateTime\")\nw1=Window().partitionBy(\"UID\").orderBy(\"DateTime\")\nw2=Window().partitionBy(\"UID\",\"inc_sum\").orderBy(\"DateTime\")\nw3=Window().partitionBy(\"UID\",\"inc_sum\")\ndf.withColumn(\"cor\",F.row_number().over(w))\\\n  .withColumn(\"yo\", F.when((F.col(\"cor\")%2!=0) & (F.col(\"result\")==30),F.lit(1)).otherwise(F.lit(0)))\\\n  .withColumn(\"inc_sum\", F.sum(\"yo\").over(w1))\\\n  .withColumn(\"cor\", F.when((F.col(\"result\")!=30) & (F.col(\"cor\")%2==0), F.lit('change')).otherwise(F.lit('no')))\\\n        .withColumn(\"row_num\", F.row_number().over(w2))\\\n        .withColumn(\"first\", F.min(\"row_num\").over(w3))\\\n        .withColumn(\"max\", F.max(\"row_num\").over(w3)).drop(\"yo\",\"row_num\",\"first\",\"max\")\\\n        .filter(\"row_num=first or row_num=max or cor='change'\")\\\n        .groupBy(\"UID\").pivot(\"result\").agg((F.collect_list(\"DateTime\")))\\\n        .withColumn(\"zip\", F.explode(F.arrays_zip(*['30','29','28','27','26','2A'])))\\\n        .select(\"UID\", \"zip.*\").show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+\n     UID|                 30|                 29|                 28|                 27|                 26|                 2A|\n+--------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+\n0000111D|2020-02-23 11:42:34|2020-02-24 11:49:34|2020-02-25 11:52:34|2020-02-26 11:34:35|2020-03-10 04:12:45|2020-02-28 11:43:35|\n0000111D|2020-03-01 11:23:35|2020-03-04 11:31:35|2020-03-06 11:17:35|2020-03-08 11:34:09|               null|2020-03-12 07:34:09|\n+--------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+\n\n</div>"]}}],"execution_count":8},{"cell_type":"code","source":["w=Window().partitionBy(\"result\").orderBy(\"DateTime\")\nw1=Window().partitionBy(\"UID\").orderBy(\"DateTime\")\nw2=Window().partitionBy(\"UID\",\"inc_sum\").orderBy(\"DateTime\")\nw3=Window().partitionBy(\"UID\",\"inc_sum\")\nw4=Window().partitionBy(\"DateTime\",\"UID\",\"inc_sum\").orderBy(\"DateTime\")\ndf.withColumn(\"cor\",F.row_number().over(w))\\\n  .withColumn(\"yo\", F.when((F.col(\"cor\")%2!=0) & (F.col(\"result\")==30),F.lit(1)).otherwise(F.lit(0)))\\\n  .withColumn(\"inc_sum\", F.sum(\"yo\").over(w1))\\\n  .withColumn(\"cor\", F.when((F.col(\"result\")!=30) & (F.col(\"cor\")%2==0), F.lit('change')).otherwise(F.lit('no')))\\\n        .withColumn(\"row_num\", F.row_number().over(w2))\\\n        .withColumn(\"first\", F.min(\"row_num\").over(w3))\\\n        .withColumn(\"max\", F.max(\"row_num\").over(w3)).drop(\"yo\",\"row_num\",\"first\",\"max\")\\\n        .filter(\"row_num=first or row_num=max or cor='change'\")\\\n        .withColumn(\"all1\", F.collect_list(\"result\").over(w3))\\\n        .withColumn(\"all\", F.array(*[F.lit(x) for x in ['30','29','28','27','26','2A']]))\\\n        .withColumn(\"except\", F.array_except(\"all\",\"all1\")[0])\\\n        .withColumn(\"result\", F.when(F.col(\"except\")+1==F.col(\"result\"), F.expr(\"\"\"sequence(int(except)+1,int(except),-1)\"\"\")).otherwise(F.expr(\"\"\"sequence(int(result),int(result),0)\"\"\")))\\\n        .withColumn(\"result\", F.when(F.col(\"result\").isNull(), F.array(F.lit(2))).otherwise(F.col(\"result\")))\\\n        .select(\"DateTime\",\"UID\",F.explode(\"result\").alias(\"result\"),\"inc_sum\")\\\n        .withColumn(\"rownum2\", F.row_number().over(w4))\\\n        .withColumn(\"DateTime\", F.when((F.col(\"rownum2\")>1), F.lit(None)).otherwise(F.col(\"DateTime\"))).orderBy(\"DateTime\")\\\n        .groupBy(\"UID\").agg(F.collect_list(\"DateTime\"))\\\n        .show(truncate=False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\nUID     |collect_list(DateTime)                                                                                                                                                                                                                 |\n+--------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n0000111D|[2020-02-23 11:42:34, 2020-02-24 11:49:34, 2020-02-25 11:52:34, 2020-02-26 11:34:35, 2020-02-28 11:43:35, 2020-03-01 11:23:35, 2020-03-04 11:31:35, 2020-03-06 11:17:35, 2020-03-08 11:34:09, 2020-03-10 04:12:45, 2020-03-12 07:34:09]|\n+--------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n</div>"]}}],"execution_count":9},{"cell_type":"code","source":["from pyspark.sql import functions as F\nfrom pyspark.sql.window import Window\nw=Window().partitionBy(\"result\").orderBy(\"DateTime\")\nw1=Window().partitionBy(\"UID\").orderBy(\"DateTime\")\nw2=Window().partitionBy(\"UID\",\"inc_sum\").orderBy(\"DateTime\")\nw3=Window().partitionBy(\"UID\",\"inc_sum\")\nw4=Window().partitionBy(\"DateTime\",\"UID\",\"inc_sum\").orderBy(\"DateTime\")\ndf.withColumn(\"cor\",F.row_number().over(w))\\\n  .withColumn(\"yo\", F.when((F.col(\"cor\")%2!=0) & (F.col(\"result\")==30),F.lit(1)).otherwise(F.lit(0)))\\\n  .withColumn(\"inc_sum\", F.sum(\"yo\").over(w1))\\\n  .withColumn(\"cor\", F.when((F.col(\"result\")!=30) & (F.col(\"cor\")%2==0), F.lit('change')).otherwise(F.lit('no')))\\\n        .withColumn(\"row_num\", F.row_number().over(w2))\\\n        .withColumn(\"first\", F.min(\"row_num\").over(w3))\\\n        .withColumn(\"max\", F.max(\"row_num\").over(w3)).drop(\"yo\",\"row_num\",\"first\",\"max\")\\\n        .filter(\"row_num=first or row_num=max or cor='change'\")\\\n        .withColumn(\"all1\", F.collect_list(\"result\").over(w3))\\\n        .withColumn(\"all\", F.array(*[F.lit(x) for x in ['30','29','28','27','26','2A']]))\\\n        .withColumn(\"except\", F.array_except(\"all\",\"all1\")[0])\\\n        .withColumn(\"result\", F.when(F.col(\"except\")+1==F.col(\"result\"), F.expr(\"\"\"sequence(int(except)+1,int(except),-1)\"\"\"))\\\n                    .otherwise(F.expr(\"\"\"sequence(int(result),int(result),0)\"\"\")))\\\n        .withColumn(\"result\", F.when(F.col(\"result\").isNull(), F.array(F.lit(2))).otherwise(F.col(\"result\")))\\\n        .select(\"DateTime\",\"UID\",F.explode(\"result\").alias(\"result\"),\"inc_sum\")\\\n        .withColumn(\"rownum2\", F.row_number().over(w4))\\\n        .withColumn(\"DateTime\", F.when((F.col(\"rownum2\")>1), F.lit(0))\\\n                    .otherwise(F.col(\"DateTime\"))).orderBy(\"DateTime\")\\\n        .groupBy(\"UID\").pivot(\"result\").agg((F.collect_list(\"DateTime\")))\\\n        .withColumn(\"zip\", F.explode(F.arrays_zip(*['30','29','28','27','26','2'])))\\\n        .select(\"UID\", \"zip.*\")\\\n        .select(\"UID\", F.col(\"30\").alias(\"start_point\"),F.col(\"29\").alias(\"1st_change\"),F.col(\"28\").alias(\"2nd_change\")\\\n                ,F.col(\"27\").alias(\"3rd_change\"),F.col(\"26\").alias(\"4th_change\"),F.col(\"2\").alias(\"5th_change\"))\\\n                .replace('0',\"datamiss\").show()\n        \n                  "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+\n     UID|        start_point|         1st_change|         2nd_change|         3rd_change|         4th_change|         5th_change|\n+--------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+\n0000111D|2020-02-23 11:42:34|2020-02-24 11:49:34|2020-02-25 11:52:34|2020-02-26 11:34:35|           datamiss|2020-02-28 11:43:35|\n0000111D|2020-03-01 11:23:35|2020-03-04 11:31:35|2020-03-06 11:17:35|2020-03-08 11:34:09|2020-03-10 04:12:45|2020-03-12 07:34:09|\n+--------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+\n\n</div>"]}}],"execution_count":10},{"cell_type":"code","source":["w=Window().partitionBy(\"result\").orderBy(\"DateTime\")\nw1=Window().partitionBy(\"UID\").orderBy(\"DateTime\")\nw2=Window().partitionBy(\"UID\",\"inc_sum\").orderBy(\"DateTime\")\nw3=Window().partitionBy(\"UID\",\"inc_sum\")\ndf.withColumn(\"cor\",F.row_number().over(w))\\\n  .withColumn(\"yo\", F.when((F.col(\"cor\")%2!=0) & (F.col(\"result\")==30),F.lit(1)).otherwise(F.lit(0)))\\\n  .withColumn(\"inc_sum\", F.sum(\"yo\").over(w1))\\\n  .withColumn(\"cor\", F.when((F.col(\"result\")!=30) & (F.col(\"cor\")%2==0), F.lit('change')).otherwise(F.lit('no')))\\\n        .withColumn(\"row_num\", F.row_number().over(w2))\\\n        .withColumn(\"first\", F.min(\"row_num\").over(w3))\\\n        .withColumn(\"max\", F.max(\"row_num\").over(w3)).drop(\"yo\",\"row_num\",\"first\",\"max\")\\\n        .filter(\"row_num=first or row_num=max or cor='change'\")\\\n        .show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------------------+--------+------+------+-------+\n           DateTime|     UID|result|   cor|inc_sum|\n+-------------------+--------+------+------+-------+\n2020-02-23 11:42:34|0000111D|    30|    no|      1|\n2020-02-24 11:49:34|0000111D|    29|change|      1|\n2020-02-25 11:52:34|0000111D|    28|change|      1|\n2020-02-26 11:34:35|0000111D|    27|change|      1|\n2020-02-28 11:43:35|0000111D|    2A|    no|      1|\n2020-03-01 11:23:35|0000111D|    30|    no|      2|\n2020-03-04 11:31:35|0000111D|    29|change|      2|\n2020-03-06 11:17:35|0000111D|    28|change|      2|\n2020-03-08 11:34:09|0000111D|    27|change|      2|\n2020-03-10 04:12:45|0000111D|    26|change|      2|\n2020-03-12 07:34:09|0000111D|    2A|    no|      2|\n+-------------------+--------+------+------+-------+\n\n</div>"]}}],"execution_count":11},{"cell_type":"code","source":["UID       start_point         1st_change           2nd_change            3rd change             4th_change            5th change    \n\n0000111D  2020-02-23 11:42:34 2020-02-24 11:49:34  2020-02-25 11:52:34   2020-02-26 11:34:35    datamiss              2020-02-28 11:43:35\n0000111D  2020-03-01 11:23:35 2020-03-04 11:31:35  2020-03-06 11:17:35   2020-03-08 11:34:09    2020-03-10 04:12:45   2020-03-12 07:34:09"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["list=[['31 Mar 2020'],\n      ['2  Apr 2020'],\n      ['29 Jan 2019'],\n      ['8  Sep 2019']]\n\ndf=spark.createDataFrame(list,['Date'])\ndf.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------+\n       Date|\n+-----------+\n31 Mar 2020|\n2  Apr 2020|\n29 Jan 2019|\n8  Sep 2019|\n+-----------+\n\n</div>"]}}],"execution_count":13},{"cell_type":"code","source":["df.withColumn(\"new_dt\", F.to_date(F.col(\"Date\"),\"dd MMM yyyy\")).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------+----------+\n       Date|    new_dt|\n+-----------+----------+\n31 Mar 2020|2020-03-31|\n2  Apr 2020|      null|\n29 Jan 2019|2019-01-29|\n8  Sep 2019|      null|\n+-----------+----------+\n\n</div>"]}}],"execution_count":14},{"cell_type":"code","source":["df.withColumn(\"length\", F.length(F.regexp_replace(\"Date\",'\\ ','')))\\\n  .withColumn(\"form\", F.when(F.col(\"length\")<9, F.concat(F.lit(0),F.regexp_replace(\"Date\",'\\ ',''))).otherwise(F.regexp_replace(\"Date\",'\\ ','')))\\\n  .withColumn(\"Date\", F.date_format(F.to_date(\"form\",'ddMMMyyyy'),'dd-MM-yyyy')).drop(\"length\",\"form\").show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+\n      Date|\n+----------+\n31-03-2020|\n02-04-2020|\n29-01-2019|\n08-09-2019|\n+----------+\n\n</div>"]}}],"execution_count":15},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["df.withColumn(\"regex\", F.regexp_replace(\"Date\",\"\\ \",\"\"))\\\n  .withColumn(\"Date\", F.when(F.length(\"regex\")<9, F.concat(F.lit(0),F.col(\"regex\")))\\\n              .otherwise(F.col(\"regex\"))).drop(\"regex\")\\\n  .withColumn(\"Date\", F.to_date(\"Date\",'ddMMMyyyy'))\\\n  .withColumn(\"Year\", F.year(\"Date\"))\\\n  .withColumn(\"Month\",F.month(\"Date\"))\\\n  .withColumn(\"Day\", F.dayofmonth(\"Date\"))\\\n  .withColumn(\"Date_Format2\", F.date_format(\"Date\", 'dd-MM-yyyy'))\\\n  .show()\n "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+----+-----+---+------------+\n      Date|Year|Month|Day|Date_Format2|\n+----------+----+-----+---+------------+\n2020-03-31|2020|    3| 31|  31-03-2020|\n2020-04-02|2020|    4|  2|  02-04-2020|\n2019-01-29|2019|    1| 29|  29-01-2019|\n2019-09-08|2019|    9|  8|  08-09-2019|\n+----------+----+-----+---+------------+\n\n</div>"]}}],"execution_count":17},{"cell_type":"code","source":["import pandas as pd\ndata = {'date': ['2014-01-01', '2014-01-02', '2014-01-03', '2014-01-04', '2014-01-05', '2014-01-06'],\n     'flat': ['A;A;B', 'D;P;E;P;P', 'H;X', 'P;Q;G', 'S;T;U', 'G;C;G']}\n\ndata['date'] = pd.to_datetime(data['date'])\n\ndata = pd.DataFrame(data)\ndata['date'] = pd.to_datetime(data['date'])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":18},{"cell_type":"code","source":["reduce(array<T>, B, function<B, T, B>, function<B, R>)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-cyan-fg\">  File </span><span class=\"ansi-green-fg\">&#34;&lt;command-2553652638713658&gt;&#34;</span><span class=\"ansi-cyan-fg\">, line </span><span class=\"ansi-green-fg\">1</span>\n<span class=\"ansi-red-fg\">    reduce(array&lt;T&gt;, B, function&lt;B, T, B&gt;, function&lt;B, R&gt;)</span>\n                   ^\n<span class=\"ansi-red-fg\">SyntaxError</span><span class=\"ansi-red-fg\">:</span> invalid syntax\n</div>"]}}],"execution_count":19},{"cell_type":"code","source":["df=spark.createDataFrame(data)\ndf.withColumn(\"list\", F.split(\"flat\",\"\\;\"))\\\n  .withColumn(\"occurances\", F.expr(\"\"\"array_sort(transform(array_distinct(list), x-> aggregate(list, 0,(acc,t)->acc+IF(t=x,1,0))))\"\"\"))\\\n  .withColumn(\"max\", F.array_max(\"occurances\"))\\\n  .show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------------------+---------+---------------+----------+---+\n               date|     flat|           list|occurances|max|\n+-------------------+---------+---------------+----------+---+\n2014-01-01 00:00:00|    A;A;B|      [A, A, B]|    [1, 2]|  2|\n2014-01-02 00:00:00|D;P;E;P;P|[D, P, E, P, P]| [1, 1, 3]|  3|\n2014-01-03 00:00:00|      H;X|         [H, X]|    [1, 1]|  1|\n2014-01-04 00:00:00|    P;Q;G|      [P, Q, G]| [1, 1, 1]|  1|\n2014-01-05 00:00:00|    S;T;U|      [S, T, U]| [1, 1, 1]|  1|\n2014-01-06 00:00:00|    G;C;G|      [G, C, G]|    [1, 2]|  2|\n+-------------------+---------+---------------+----------+---+\n\n</div>"]}}],"execution_count":20},{"cell_type":"code","source":["import pandas as pd\nimport datetime\n\ndata = {'date': ['2014-01-01', '2014-01-02', '2014-01-03', '2014-01-04', '2014-01-05', '2014-01-06'],\n     'customerid': [1, 2, 2, 3, 4, 3], 'productids': ['A;B', 'D;E', 'H;X', 'P;Q;G', 'S;T;U', 'C;G']}\ndata = pd.DataFrame(data)\ndata['date'] = pd.to_datetime(data['date'])\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":21},{"cell_type":"code","source":["df=spark.createDataFrame(data)\n\nx = 2\n\nwin = Window().partitionBy('customerid').orderBy(F.col(\"date\").cast(\"long\")).rangeBetween(-(86400*x), Window.currentRow)\ntest = df.withColumn(\"productids\", F.array_distinct(F.split(\"productids\", \"\\;\")))\\\n    .withColumn(\"flat_col\", F.array_distinct(F.flatten((F.collect_list(\"productids\").over(win))))).orderBy(F.col(\"date\")).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------------------+----------+----------+------------+\n               date|customerid|productids|    flat_col|\n+-------------------+----------+----------+------------+\n2014-01-01 00:00:00|         1|    [A, B]|      [A, B]|\n2014-01-02 00:00:00|         2|    [D, E]|      [D, E]|\n2014-01-03 00:00:00|         2|    [H, X]|[D, E, H, X]|\n2014-01-04 00:00:00|         3| [P, Q, G]|   [P, Q, G]|\n2014-01-05 00:00:00|         4| [S, T, U]|   [S, T, U]|\n2014-01-06 00:00:00|         3|    [C, G]|[P, Q, G, C]|\n+-------------------+----------+----------+------------+\n\n</div>"]}}],"execution_count":22},{"cell_type":"code","source":["df=spark.createDataFrame(data)\n\nx = 2\n\nwin = Window().partitionBy('customerid').orderBy(F.col(\"date\").cast(\"long\")).rangeBetween(-(86400*x), Window.currentRow)\ntest = df.withColumn(\"productids\", F.array_distinct(F.split(\"productids\", \"\\;\")))\\\n    .withColumn(\"flat_col\", F.flatten(F.collect_list(\"productids\").over(win)))\\\n    .withColumn(\"occurances\", F.expr(\"\"\"filter(transform(productids, x->\\\n     IF(aggregate(flat_col, 0,(acc,t)->acc+IF(t=x,1,0))>1,x,null)),y->y!='null')\"\"\"))\\\n    .drop(\"flat_col\").orderBy(\"date\").show()\n \n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------------------+----------+----------+----------+\n               date|customerid|productids|occurances|\n+-------------------+----------+----------+----------+\n2014-01-01 00:00:00|         1|    [A, B]|        []|\n2014-01-02 00:00:00|         2|    [D, E]|        []|\n2014-01-03 00:00:00|         2|    [H, X]|        []|\n2014-01-04 00:00:00|         3| [P, Q, G]|        []|\n2014-01-05 00:00:00|         4| [S, T, U]|        []|\n2014-01-06 00:00:00|         3|    [C, G]|       [G]|\n+-------------------+----------+----------+----------+\n\n</div>"]}}],"execution_count":23},{"cell_type":"code","source":["\ndf.join(df.select(F.col(\"productids\").alias(\"productids1\"),F.col(\"customerid\").alias(\"customerid1\")),\\\n        (F.col(\"productids\")!=F.col(\"productids1\"))& (F.col(\"customerid\")==F.col(\"customerid1\")))\\\n  .withColumn(\"productids\", F.split(\"productids\",\"\\;\"))\\\n              .withColumn(\"productids1\", F.split(\"productids1\",\"\\;\")).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------------------+----------+----------+-----------+-----------+\n               date|customerid|productids|productids1|customerid1|\n+-------------------+----------+----------+-----------+-----------+\n2014-01-04 00:00:00|         3| [P, Q, G]|     [C, G]|          3|\n2014-01-06 00:00:00|         3|    [C, G]|  [P, Q, G]|          3|\n2014-01-02 00:00:00|         2|    [D, E]|     [H, X]|          2|\n2014-01-03 00:00:00|         2|    [H, X]|     [D, E]|          2|\n+-------------------+----------+----------+-----------+-----------+\n\n</div>"]}}],"execution_count":24},{"cell_type":"code","source":["list=[[ 101, 102,'MTD0001',    1,    10,3,6,10,13],\n      [ 101, 102,'MTD0002',     2,    12,4,8,11,14],\n      [ 101, 102,'MTD0003',     3,    13,5,9,12,15]]\n\ndf=spark.createDataFrame(list,['dim1','dim2','byvar','input1','input2','input3','input4','input5','input6'])\n\n\ndf.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----+----+-------+------+------+------+------+------+------+\ndim1|dim2|  byvar|input1|input2|input3|input4|input5|input6|\n+----+----+-------+------+------+------+------+------+------+\n 101| 102|MTD0001|     1|    10|     3|     6|    10|    13|\n 101| 102|MTD0002|     2|    12|     4|     8|    11|    14|\n 101| 102|MTD0003|     3|    13|     5|     9|    12|    15|\n+----+----+-------+------+------+------+------+------+------+\n\n</div>"]}}],"execution_count":25},{"cell_type":"code","source":["from pyspark.sql import functions as F\ndf.withColumn(\"vals\",\\\nF.explode(F.arrays_zip(F.array([F.array(F.lit(x),F.col(x)) for x in df.columns if x.startswith(\"input\")]))))\\\n.select(\"dim1\", \"dim2\",\"byvar\",\"vals.*\").withColumn(\"TRAMS_NAME\", F.element_at(\"0\",1))\\\n                                                    .withColumn(\"VALUES\", F.element_at(\"0\",2)).drop(\"0\").show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----+----+-------+----------+------+\ndim1|dim2|  byvar|TRAMS_NAME|VALUES|\n+----+----+-------+----------+------+\n 101| 102|MTD0001|    input1|     1|\n 101| 102|MTD0001|    input2|    10|\n 101| 102|MTD0001|    input3|     3|\n 101| 102|MTD0001|    input4|     6|\n 101| 102|MTD0001|    input5|    10|\n 101| 102|MTD0001|    input6|    13|\n 101| 102|MTD0002|    input1|     2|\n 101| 102|MTD0002|    input2|    12|\n 101| 102|MTD0002|    input3|     4|\n 101| 102|MTD0002|    input4|     8|\n 101| 102|MTD0002|    input5|    11|\n 101| 102|MTD0002|    input6|    14|\n 101| 102|MTD0003|    input1|     3|\n 101| 102|MTD0003|    input2|    13|\n 101| 102|MTD0003|    input3|     5|\n 101| 102|MTD0003|    input4|     9|\n 101| 102|MTD0003|    input5|    12|\n 101| 102|MTD0003|    input6|    15|\n+----+----+-------+----------+------+\n\n</div>"]}}],"execution_count":26},{"cell_type":"code","source":["from pyspark.sql import functions as F\ndf.withColumn(\"vals\",\\\nF.explode(F.arrays_zip(F.array([F.array(F.lit(x),F.col(x)) for x in df.columns if x.startswith(\"input\")]))))\\\n.select(\"dim1\", \"dim2\",\"byvar\",F.col(\"vals.*\")).withColumnRenamed(\"0\",\"vals\")\\\n                                               .withColumn(\"\".show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----+----+-------+------------+\ndim1|dim2|  byvar|        vals|\n+----+----+-------+------------+\n 101| 102|MTD0001| [input1, 1]|\n 101| 102|MTD0001|[input2, 10]|\n 101| 102|MTD0001| [input3, 3]|\n 101| 102|MTD0001| [input4, 6]|\n 101| 102|MTD0001|[input5, 10]|\n 101| 102|MTD0001|[input6, 13]|\n 101| 102|MTD0002| [input1, 2]|\n 101| 102|MTD0002|[input2, 12]|\n 101| 102|MTD0002| [input3, 4]|\n 101| 102|MTD0002| [input4, 8]|\n 101| 102|MTD0002|[input5, 11]|\n 101| 102|MTD0002|[input6, 14]|\n 101| 102|MTD0003| [input1, 3]|\n 101| 102|MTD0003|[input2, 13]|\n 101| 102|MTD0003| [input3, 5]|\n 101| 102|MTD0003| [input4, 9]|\n 101| 102|MTD0003|[input5, 12]|\n 101| 102|MTD0003|[input6, 15]|\n+----+----+-------+------------+\n\n</div>"]}}],"execution_count":27},{"cell_type":"code","source":["import pandas as pd\ndf = pd.DataFrame({'Name': ['John Doe', 'Jane Smith', 'John Doe', 'Jane Smith','Jack Dawson','John Doe']})\ndf4=spark.createDataFrame(df)\ndf4.show()\ndf4.withColumn(\"UUID\", F.sha2(\"Name\", 256)).show(truncate=False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------+\n       Name|\n+-----------+\n   John Doe|\n Jane Smith|\n   John Doe|\n Jane Smith|\nJack Dawson|\n   John Doe|\n+-----------+\n\n+-----------+----------------------------------------------------------------+\nName       |UUID                                                            |\n+-----------+----------------------------------------------------------------+\nJohn Doe   |6cea57c2fb6cbc2a40411135005760f241fffc3e5e67ab99882726431037f908|\nJane Smith |a2dd3acadb1c9dcd956216993056a7f50a9db6e3a16c60b35482139b5349c288|\nJohn Doe   |6cea57c2fb6cbc2a40411135005760f241fffc3e5e67ab99882726431037f908|\nJane Smith |a2dd3acadb1c9dcd956216993056a7f50a9db6e3a16c60b35482139b5349c288|\nJack Dawson|9ed2a49adb17e10efab2a2d32f0f8e74f3f76226dc606c8cc0f0c0d3270b73b9|\nJohn Doe   |6cea57c2fb6cbc2a40411135005760f241fffc3e5e67ab99882726431037f908|\n+-----------+----------------------------------------------------------------+\n\n</div>"]}}],"execution_count":28},{"cell_type":"code","source":["list=[[0,18,'PROPERTY_1',0.1],\n     [19,40,'PROPERTY_1',0.8],\n      [0,20,'PROPERTY_2',0.7],\n     [20,24,'PROPERTY_2',0.3],\n     [25,40,'PROPERTY_2',0.7],\n     [0,40,'PROPERTY_3',0.5]]\n\n\ndf2=spark.createDataFrame(list,['START_TIME','END_TIME','PROPERTY_NAME','VALUE'])\n\n\nlist2=[['Event_1',13,1,0,1],\n       ['Event_2',24,0,1,1],\n       ['Event_3',35,1,0,0]]\n\n\ndf1=spark.createDataFrame(list2,['EVENT_INDEX','EVENT_TIME','PROPERTY_1','PROPERTY_2','PROPERTY_3'])\n\ndf1.show()\ndf2.show()\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------+----------+----------+----------+----------+\nEVENT_INDEX|EVENT_TIME|PROPERTY_1|PROPERTY_2|PROPERTY_3|\n+-----------+----------+----------+----------+----------+\n    Event_1|        13|         1|         0|         1|\n    Event_2|        24|         0|         1|         1|\n    Event_3|        35|         1|         0|         0|\n+-----------+----------+----------+----------+----------+\n\n+----------+--------+-------------+-----+\nSTART_TIME|END_TIME|PROPERTY_NAME|VALUE|\n+----------+--------+-------------+-----+\n         0|      18|   PROPERTY_1|  0.1|\n        19|      40|   PROPERTY_1|  0.8|\n         0|      20|   PROPERTY_2|  0.7|\n        20|      24|   PROPERTY_2|  0.3|\n        25|      40|   PROPERTY_2|  0.7|\n         0|      40|   PROPERTY_3|  0.5|\n+----------+--------+-------------+-----+\n\n</div>"]}}],"execution_count":29},{"cell_type":"code","source":["df1.withColumn(\"PROPERTIES\",\\\nF.explode(F.arrays_zip(F.array([F.array(F.lit(x),F.col(x)) for x in df1.columns if x.startswith(\"PROPERTY_\")]))))\\\n.select(\"EVENT_INDEX\", \"EVENT_TIME\",\"PROPERTIES.*\",\\\n       *[x for x in df1.columns if x.startswith(\"PROPERTY_\")]).withColumn(\"PROPERTY\", F.element_at(\"0\",1))\\\n                                                    .withColumn(\"PROPERTY_VALUE\", F.element_at(\"0\",2)).drop(\"0\")\\\n.filter('PROPERTY_VALUE=1').join(df2, (df1.EVENT_TIME>=df2.START_TIME) & (df1.EVENT_TIME<=df2.END_TIME)& \\\n(F.col(\"PROPERTY\")==df2.PROPERTY_NAME)).groupBy(\"EVENT_INDEX\").agg(F.first(\"EVENT_TIME\").alias(\"EVENT_TIME\"),\\\n*[F.first(x).alias(x) for x in df1.columns if x.startswith(\"PROPERTY_\")],\\\n(F.sum(\"VALUE\").alias(\"TOTAL_VALUE\"))).orderBy(\"EVENT_TIME\").show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------+----------+----------+----------+----------+-----------+\nEVENT_INDEX|EVENT_TIME|PROPERTY_1|PROPERTY_2|PROPERTY_3|TOTAL_VALUE|\n+-----------+----------+----------+----------+----------+-----------+\n    Event_1|        13|         1|         0|         1|        0.6|\n    Event_2|        24|         0|         1|         1|        0.8|\n    Event_3|        35|         1|         0|         0|        0.8|\n+-----------+----------+----------+----------+----------+-----------+\n\n</div>"]}}],"execution_count":30},{"cell_type":"code","source":["df3=df1.withColumn(\"PROPERTIES\",\\\nF.explode(F.arrays_zip(F.array([F.array(F.lit(x),F.col(x)) for x in df1.columns if x.startswith(\"PROPERTY_\")]))))\\\n.select(\"EVENT_INDEX\", \"EVENT_TIME\",\"PROPERTIES.*\",\\\n       *[x for x in df1.columns if x.startswith(\"PROPERTY_\")]).withColumn(\"PROPERTY\", F.col(\"0\")[0])\\\n                                                    .withColumn(\"PROPERTY_VALUE\", F.col(\"0\")[1]).drop(\"0\")\ndf3.filter('PROPERTY_VALUE=1').join(df2, (df3.EVENT_TIME>=df2.START_TIME) & (df3.EVENT_TIME<=df2.END_TIME) & (df3.PROPERTY==df2.PROPERTY_NAME)).groupBy(\"EVENT_INDEX\").agg(F.first(\"EVENT_TIME\").alias(\"EVENT_TIME\"),\\\n*[F.first(x).alias(x) for x in df3.columns if x.startswith(\"PROPERTY_\") and x!='PROPERTY_VALUE'],\\\n(F.sum(\"VALUE\").alias(\"TOTAL_VALUE\"))).orderBy(\"EVENT_TIME\").show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------+----------+----------+----------+----------+-----------+\nEVENT_INDEX|EVENT_TIME|PROPERTY_1|PROPERTY_2|PROPERTY_3|TOTAL_VALUE|\n+-----------+----------+----------+----------+----------+-----------+\n    Event_1|        13|         1|         0|         1|        0.6|\n    Event_2|        24|         0|         1|         1|        0.8|\n    Event_3|        35|         1|         0|         0|        0.8|\n+-----------+----------+----------+----------+----------+-----------+\n\n</div>"]}}],"execution_count":31},{"cell_type":"code","source":["df3.filter('PROPERTY_VALUE=1').join(df2, (df3.EVENT_TIME>=df2.START_TIME) & (df3.EVENT_TIME<=df2.END_TIME) & (df3.PROPERTY==df2.PROPERTY_NAME)).groupBy(\"EVENT_INDEX\").agg(F.first(\"EVENT_TIME\").alias(\"EVENT_TIME\"),\\\n*[F.first(x).alias(x) for x in df3.columns if x.startswith(\"PROPERTY_\")],\\\n(F.sum(\"VALUE\").alias(\"TOTAL_VALUE\"))).orderBy(\"EVENT_TIME\").show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------+----------+----------+----------+----------+--------------+-----------+\nEVENT_INDEX|EVENT_TIME|PROPERTY_1|PROPERTY_2|PROPERTY_3|PROPERTY_VALUE|TOTAL_VALUE|\n+-----------+----------+----------+----------+----------+--------------+-----------+\n    Event_1|        13|         1|         0|         1|             1|        0.6|\n    Event_2|        24|         0|         1|         1|             1|        0.8|\n    Event_3|        35|         1|         0|         0|             1|        0.8|\n+-----------+----------+----------+----------+----------+--------------+-----------+\n\n</div>"]}}],"execution_count":32},{"cell_type":"code","source":["df3=df1.withColumn(\"PROPERTIES\",\\\nF.explode(F.arrays_zip(F.array([F.array(F.lit(x),F.col(x)) for x in df1.columns if x.startswith(\"PROPERTY_\")]))))\\\n.select(\"EVENT_INDEX\", \"EVENT_TIME\",\"PROPERTIES.*\",\\\n       \"PROPERTY_1\",\"PROPERTY_2\",\"PROPERTY_3\").withColumn(\"PROPERTY\", F.col(\"0\")[0])\\\n                                                    .withColumn(\"PROPERTY_VALUE\", F.col(\"0\")[1]).drop(\"0\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":33},{"cell_type":"code","source":["df3.filter('PROPERTY_VALUE=1').join(df2, (df3.EVENT_TIME>=df2.START_TIME) & (df3.EVENT_TIME<=df2.END_TIME) & (df3.PROPERTY==df2.PROPERTY_NAME)).groupBy(\"EVENT_INDEX\").agg(F.first(\"EVENT_TIME\").alias(\"EVENT_TIME\"),\\\nF.first(\"PROPERTY_1\").alias(\"PROPERTY_1\"),\\\nF.first(\"PROPERTY_2\").alias(\"PROPERTY_2\"),\\\nF.first(\"PROPERTY_3\").alias(\"PROPERTY_3\"),\n(F.sum(\"VALUE\").alias(\"TOTAL_VALUE\"))).orderBy(\"EVENT_TIME\").show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------+----------+----------+----------+----------+-----------+\nEVENT_INDEX|EVENT_TIME|PROPERTY_1|PROPERTY_2|PROPERTY_3|TOTAL_VALUE|\n+-----------+----------+----------+----------+----------+-----------+\n    Event_1|        13|         1|         0|         1|        0.6|\n    Event_2|        24|         0|         1|         1|        0.8|\n    Event_3|        35|         1|         0|         0|        0.8|\n+-----------+----------+----------+----------+----------+-----------+\n\n</div>"]}}],"execution_count":34},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":35}],"metadata":{"name":"stackhelp44","notebookId":2731623517538990},"nbformat":4,"nbformat_minor":0}
