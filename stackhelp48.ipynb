{"cells":[{"cell_type":"code","source":["from pyspark.sql import functions as F \nfrom pyspark.sql.window import Window\nfrom pyspark.sql.types import *\nfrom pyspark.storagelevel import StorageLevel"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["list=[['cm',30.0,50.0],\n     ['cm',40.0,70.0],\n     ['cm',20.0,85.0],\n     ['cm',20.0,85.0],\n     ['cm',30.0,76.0],\n     ['cm',43.0,65.0],\n     ['Meter',0.2,.65],\n     ['Meter',0.4,.68],\n     ['Meter',0.5,.8]]\n\ndf=spark.createDataFrame(list,['unit','ref_low','ref_high'])\n\ndf.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+-------+--------+\n unit|ref_low|ref_high|\n+-----+-------+--------+\n   cm|   30.0|    50.0|\n   cm|   40.0|    70.0|\n   cm|   20.0|    85.0|\n   cm|   20.0|    85.0|\n   cm|   30.0|    76.0|\n   cm|   43.0|    65.0|\nMeter|    0.2|    0.65|\nMeter|    0.4|    0.68|\nMeter|    0.5|     0.8|\n+-----+-------+--------+\n\n</div>"]}}],"execution_count":2},{"cell_type":"code","source":["#I wanted to convert some of the cm values (ref_low = 20 and ref_low <40, & ref_high > 70 and ref_high <90,) to meter using the formula (cm/100). I tried to use Pyspark UDF\n\nfrom pyspark.sql import functions as F\ndf.withColumn(\"ref_low\", F.when((F.col(\"unit\")=='cm')&((F.col(\"ref_low\")<40)&\\\n                                 (F.col(\"ref_low\")==20)), F.col(\"ref_low\")/100)\\\n             .otherwise(F.col(\"ref_low\")))\\\n  .withColumn(\"ref_high\", F.when((F.col(\"unit\")=='cm')&((F.col(\"ref_high\")<90)&\\\n                                  (F.col(\"ref_high\")>70)),F.col(\"ref_high\")/100)\\\n              .otherwise(F.col(\"ref_high\"))).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+-------+--------+\n unit|ref_low|ref_high|\n+-----+-------+--------+\n   cm|   30.0|    50.0|\n   cm|   40.0|    70.0|\n   cm|    0.2|    0.85|\n   cm|    0.2|    0.85|\n   cm|   30.0|    0.76|\n   cm|   43.0|    65.0|\nMeter|    0.2|    0.65|\nMeter|    0.4|    0.68|\nMeter|    0.5|     0.8|\n+-----+-------+--------+\n\n</div>"]}}],"execution_count":3},{"cell_type":"code","source":["list1=[[1,-2],\n      [1,-2],\n      [1,2],\n      [1,3],\n      [1,4]]\n\nlist2=[[2,3],\n       [3,4]]\n\ndataframe=spark.createDataFrame(list1,['col1','col2'])\n\ndf=spark.createDataFrame(list2,['col1','col2'])\n\n\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["dataframe.join(df.select(\"col2\"),[\"col2\"],how='left_anti').show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----+----+\ncol2|col1|\n+----+----+\n  -2|   1|\n  -2|   1|\n   2|   1|\n+----+----+\n\n</div>"]}}],"execution_count":5},{"cell_type":"code","source":["dataframe.filter(~F.col(\"col2\").isin([x[0] for x in df.select(\"col2\").collect()])).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----+----+\ncol1|col2|\n+----+----+\n   1|  -2|\n   1|  -2|\n   1|   2|\n+----+----+\n\n</div>"]}}],"execution_count":6},{"cell_type":"code","source":["df.filter(~F.col(\"col2\").isin([x[0] for x in df1.select(\"col2\").collect()])).show()\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----+----+\ncol1|col2|\n+----+----+\n   1|   2|\n   1|   2|\n   1|   2|\n+----+----+\n\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":["df.except(df1.select(\"col2\")).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-cyan-fg\">  File </span><span class=\"ansi-green-fg\">&#34;&lt;command-4348710841451748&gt;&#34;</span><span class=\"ansi-cyan-fg\">, line </span><span class=\"ansi-green-fg\">1</span>\n<span class=\"ansi-red-fg\">    df.except(df1.select(&#34;col2&#34;)).show()</span>\n            ^\n<span class=\"ansi-red-fg\">SyntaxError</span><span class=\"ansi-red-fg\">:</span> invalid syntax\n</div>"]}}],"execution_count":8},{"cell_type":"code","source":["df.filter(~F.col(\"col2\").isin(b)).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----+----+\ncol1|col2|\n+----+----+\n   1|   2|\n   1|   2|\n   1|   2|\n+----+----+\n\n</div>"]}}],"execution_count":9},{"cell_type":"code","source":["df = spark.createDataFrame(\n    [(1, [\"foo\", \"bar\"], {\"x\": 1.0}), (2, [], {}), (3, None, None)],\n    (\"id\", \"an_array\", \"a_map\")\n)\ndf.show()\ndf.select(\"id\", \"an_array\", F.explode_outer(\"a_map\")).show()\ndf.select(\"id\", \"an_array\", F.explode(\"a_map\")).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+----------+----------+\n id|  an_array|     a_map|\n+---+----------+----------+\n  1|[foo, bar]|[x -&gt; 1.0]|\n  2|        []|        []|\n  3|      null|      null|\n+---+----------+----------+\n\n+---+----------+----+-----+\n id|  an_array| key|value|\n+---+----------+----+-----+\n  1|[foo, bar]|   x|  1.0|\n  2|        []|null| null|\n  3|      null|null| null|\n+---+----------+----+-----+\n\n+---+----------+---+-----+\n id|  an_array|key|value|\n+---+----------+---+-----+\n  1|[foo, bar]|  x|  1.0|\n+---+----------+---+-----+\n\n</div>"]}}],"execution_count":10},{"cell_type":"code","source":["list=[['A','2020-04-08T01:53:54.932000','Org1','wifi',60,372717],\n                      ['A','2020-04-08T02:40:38.661000','Org1','wifi',194,819040],\n                       ['A','2020-04-08T21:45:10.207000','Org1','wifi',8885,3449150],\n                        ['A','2020-04-09T00:15:28.838000','Org1','wifi',14770,3572589],\n                         ['A','2020-04-09T04:27:33.424000','Org1','remote',0,0],\n                          ['A','2020-04-09T04:29:25.189000','Org1','wifi',60,7495],\n                           ['A','2020-04-09T04:44:21.397000','Org1','remote',60,553356],\n                            ['A','2020-04-09T04:50:40.406000','Org1','wifi',60,662467],\n                             ['A','2020-04-10T00:00:50.636000','Org1','remote',0,72],\n                              ['A','2020-04-10T04:20:28.831000','Org1','remote',6,497],\n                               ['A','2020-04-10T04:31:35.336000','Org1','remote',0,22],\n                                ['B','2020-04-08T21:56:58.502000','Org2','remote',0,0],\n                                 ['B','2020-04-08T22:01:19.534000','Org2','wifi',0,0],\n                                  ['B','2020-04-08T22:10:15.891000','Org2','wifi',60,187891],\n                                   ['B','2020-04-08T22:16:41.499000','Org2','wifi',1620,207674],\n                                    ['B','2020-04-09T01:55:02.772000','Org2','wifi',360,426232],\n                                     ['B','2020-04-09T02:03:32.735000','Org2','wifi',60,374827],\n                                      ['B','2020-04-09T02:06:16.509000','Org2','wifi',60,386518],\n                                       ['B','2020-04-09T02:13:33.497000','Org2','remote',60,373609],\n                                        ['B','2020-04-09T02:17:19.176000','Org2','wifi',133,400417],\n                                         ['B','2020-04-10T23:10:15.654000','Org2','remote',0,212],\n                                          ['B','2020-04-10T23:10:41.749000','Org2','remote',1,285]]\n\ndf=spark.createDataFrame(list,[\"deviceId\",\"time-started\",\"OrgId\",\"type\",\"duration\",\"packet\"])\n\n\ndf.show(truncate=False)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+--------------------------+-----+------+--------+-------+\ndeviceId|time-started              |OrgId|type  |duration|packet |\n+--------+--------------------------+-----+------+--------+-------+\nA       |2020-04-08T01:53:54.932000|Org1 |wifi  |60      |372717 |\nA       |2020-04-08T02:40:38.661000|Org1 |wifi  |194     |819040 |\nA       |2020-04-08T21:45:10.207000|Org1 |wifi  |8885    |3449150|\nA       |2020-04-09T00:15:28.838000|Org1 |wifi  |14770   |3572589|\nA       |2020-04-09T04:27:33.424000|Org1 |remote|0       |0      |\nA       |2020-04-09T04:29:25.189000|Org1 |wifi  |60      |7495   |\nA       |2020-04-09T04:44:21.397000|Org1 |remote|60      |553356 |\nA       |2020-04-09T04:50:40.406000|Org1 |wifi  |60      |662467 |\nA       |2020-04-10T00:00:50.636000|Org1 |remote|0       |72     |\nA       |2020-04-10T04:20:28.831000|Org1 |remote|6       |497    |\nA       |2020-04-10T04:31:35.336000|Org1 |remote|0       |22     |\nB       |2020-04-08T21:56:58.502000|Org2 |remote|0       |0      |\nB       |2020-04-08T22:01:19.534000|Org2 |wifi  |0       |0      |\nB       |2020-04-08T22:10:15.891000|Org2 |wifi  |60      |187891 |\nB       |2020-04-08T22:16:41.499000|Org2 |wifi  |1620    |207674 |\nB       |2020-04-09T01:55:02.772000|Org2 |wifi  |360     |426232 |\nB       |2020-04-09T02:03:32.735000|Org2 |wifi  |60      |374827 |\nB       |2020-04-09T02:06:16.509000|Org2 |wifi  |60      |386518 |\nB       |2020-04-09T02:13:33.497000|Org2 |remote|60      |373609 |\nB       |2020-04-09T02:17:19.176000|Org2 |wifi  |133     |400417 |\n+--------+--------------------------+-----+------+--------+-------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":11},{"cell_type":"code","source":["w=Window().partitionBy(\"deviceId\").orderBy(F.col(\"time-started\").cast(\"long\")).rangeBetween(Window.currentRow,24*60*60)\ndf2=df.withColumn(\"time-started\", F.to_timestamp(\"time-started\", \"yyyy-MM-dd'T'HH:mm:ss\"))\\\n      .withColumn(\"time-started-2\", F.col(\"time-started\"))\\\n      .withColumn(\"duration\", F.sum(\"duration\").over(w))\\\n      .withColumn(\"packet\", F.sum(\"packet\").over(w))\n\n\nfrom pyspark.sql import functions as F\ndf2.groupBy(\"deviceId\",F.window(\"time-started\",\"1440 minutes\"))\\\n  .agg(F.first(\"duration\").alias(\"duration\"),\\\n      F.first(\"packet\").alias(\"packet\")).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+--------------------+--------+-------+\ndeviceId|              window|duration| packet|\n+--------+--------------------+--------+-------+\n       B|[2020-04-08 00:00...|    2353|2357168|\n       B|[2020-04-09 00:00...|     673|1961603|\n       B|[2020-04-10 00:00...|       1|    497|\n       A|[2020-04-08 00:00...|   23909|8213496|\n       A|[2020-04-09 00:00...|   14950|4795979|\n       A|[2020-04-10 00:00...|       6|    591|\n+--------+--------------------+--------+-------+\n\n</div>"]}}],"execution_count":12},{"cell_type":"code","source":["+--------+-------------------+-----+------+--------+-------+\n|deviceId|       time-started|OrgId|  type|duration| packet|\n+--------+-------------------+-----+------+--------+-------+\n|       A|2020-04-08 01:53:54| Org1|  wifi|   23909|8213496|\n|       A|2020-04-09 04:27:33| Org1|remote|     186|1223887|\n|       A|2020-04-10 04:31:35| Org1|remote|       0|     22|\n|       B|2020-04-08 21:56:58| Org2|remote|    2353|2357168|\n|       B|2020-04-10 23:10:15| Org2|remote|       1|    497|\n+--------+-------------------+-----+------+--------+-------+"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["list=[['A','2020-04-08T01:53:54.932000','Org1','wifi',60,372717],\n      ['A','2020-04-09T04:50:40.406000','Org1','wifi',60,662467],\n                             ['A','2020-04-10T00:00:50.636000','Org1','remote',0,72],\n                              ['A','2020-04-10T04:20:28.831000','Org1','remote',6,497],\n                               ['A','2020-04-10T04:31:35.336000','Org1','remote',0,22],\n                      ['A','2020-04-08T02:40:38.661000','Org1','wifi',194,819040],\n                       ['A','2020-04-08T21:45:10.207000','Org1','wifi',8885,3449150],\n                        ['A','2020-04-09T00:15:28.838000','Org1','wifi',14770,3572589],\n                         ['A','2020-04-09T04:27:33.424000','Org1','remote',0,0],\n                          ['A','2020-04-09T04:29:25.189000','Org1','wifi',60,7495],\n                           ['A','2020-04-09T04:44:21.397000','Org1','remote',60,553356],\n                               ['B','2020-04-09T01:55:02.772000','Org2','wifi',360,426232],\n                                ['B','2020-04-08T21:56:58.502000','Org2','remote',0,0],\n                                 ['B','2020-04-08T22:01:19.534000','Org2','wifi',0,0],\n                                  ['B','2020-04-08T22:10:15.891000','Org2','wifi',60,187891],\n                                   ['B','2020-04-08T22:16:41.499000','Org2','wifi',1620,207674],\n                                     ['B','2020-04-09T02:03:32.735000','Org2','wifi',60,374827],\n                                      ['B','2020-04-09T02:06:16.509000','Org2','wifi',60,386518],\n                                       ['B','2020-04-09T02:13:33.497000','Org2','remote',60,373609],\n                                        ['B','2020-04-09T02:17:19.176000','Org2','wifi',133,400417],\n                                         ['B','2020-04-10T23:10:15.654000','Org2','remote',0,212],\n                                          ['B','2020-04-10T23:10:41.749000','Org2','remote',1,285]]\n\ndf=spark.createDataFrame(list,[\"deviceId\",\"time-started\",\"OrgId\",\"type\",\"duration\",\"packet\"])\ndf.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+--------------------+-----+------+--------+-------+\ndeviceId|        time-started|OrgId|  type|duration| packet|\n+--------+--------------------+-----+------+--------+-------+\n       A|2020-04-08T01:53:...| Org1|  wifi|      60| 372717|\n       A|2020-04-09T04:50:...| Org1|  wifi|      60| 662467|\n       A|2020-04-10T00:00:...| Org1|remote|       0|     72|\n       A|2020-04-10T04:20:...| Org1|remote|       6|    497|\n       A|2020-04-10T04:31:...| Org1|remote|       0|     22|\n       A|2020-04-08T02:40:...| Org1|  wifi|     194| 819040|\n       A|2020-04-08T21:45:...| Org1|  wifi|    8885|3449150|\n       A|2020-04-09T00:15:...| Org1|  wifi|   14770|3572589|\n       A|2020-04-09T04:27:...| Org1|remote|       0|      0|\n       A|2020-04-09T04:29:...| Org1|  wifi|      60|   7495|\n       A|2020-04-09T04:44:...| Org1|remote|      60| 553356|\n       B|2020-04-09T01:55:...| Org2|  wifi|     360| 426232|\n       B|2020-04-08T21:56:...| Org2|remote|       0|      0|\n       B|2020-04-08T22:01:...| Org2|  wifi|       0|      0|\n       B|2020-04-08T22:10:...| Org2|  wifi|      60| 187891|\n       B|2020-04-08T22:16:...| Org2|  wifi|    1620| 207674|\n       B|2020-04-09T02:03:...| Org2|  wifi|      60| 374827|\n       B|2020-04-09T02:06:...| Org2|  wifi|      60| 386518|\n       B|2020-04-09T02:13:...| Org2|remote|      60| 373609|\n       B|2020-04-09T02:17:...| Org2|  wifi|     133| 400417|\n+--------+--------------------+-----+------+--------+-------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":14},{"cell_type":"code","source":["import pandas as pd\nfrom pyspark.sql.functions import pandas_udf, PandasUDFType\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.window import Window\n\nw=Window().partitionBy(\"deviceId\").orderBy(F.col(\"time-started\").cast(\"long\")).rangeBetween(Window.currentRow,24*60*60)\ndf2=df.withColumn(\"time-started\", F.to_timestamp(\"time-started\", \"yyyy-MM-dd'T'HH:mm:ss\"))\\\n      .withColumn(\"time-started-2\", F.col(\"time-started\"))\\\n      .withColumn(\"duration\", F.sum(\"duration\").over(w))\\\n      .withColumn(\"packet\", F.sum(\"packet\").over(w))\n\n@pandas_udf(df2.schema, PandasUDFType.GROUPED_MAP)\ndef grouped_map(df1):\n   start=df1.loc[0, 'time-started']\n   for i in range(1, len(df1)):\n        if start + pd.Timedelta(days=1)>df1.loc[i,'time-started']:\n             df1.loc[i,'time-started']=start\n        else:\n             start=df1.loc[i,'time-started']    \n           \n\n   return df1\ndf2.groupby('deviceId').apply(grouped_map)\\\n.filter(F.col(\"time-started-2\")==F.col(\"time-started\"))\\\n.drop(\"time-started-2\")\\\n.orderBy(\"deviceId\")\\\n.show()\n  "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+-------------------+-----+------+--------+-------+\ndeviceId|       time-started|OrgId|  type|duration| packet|\n+--------+-------------------+-----+------+--------+-------+\n       A|2020-04-08 01:53:54| Org1|  wifi|   23909|8213496|\n       A|2020-04-09 04:27:33| Org1|remote|     186|1223887|\n       A|2020-04-10 04:31:35| Org1|remote|       0|     22|\n       B|2020-04-08 21:56:58| Org2|remote|    2353|2357168|\n       B|2020-04-10 23:10:15| Org2|remote|       1|    497|\n+--------+-------------------+-----+------+--------+-------+\n\n</div>"]}}],"execution_count":15},{"cell_type":"code","source":["w=Window().partitionBy(\"deviceId\").orderBy(F.col(\"time-started\").cast(\"long\")).rangeBetween(Window.currentRow,24*60*60)\nw1=Window().partitionBy(\"deviceId\").orderBy(F.col(\"time-started\"))\nw2=Window().partitionBy(\"deviceId\",\"sum\").orderBy(F.col(\"time-started\")).rowsBetween(Window.unboundedPreceding,Window.unboundedFollowing)\n\ndisplay(df.withColumn(\"time-started\", F.to_timestamp(\"time-started\", \"yyyy-MM-dd'T'HH:mm:ss\"))\\\n  .withColumn(\"packet1\", F.sum(\"packet\").over(w))\\\n  .withColumn(\"diff\", F.col(\"time-started\").cast(\"long\")-F.lag(\"time-started\").over(w1).cast(\"long\"))\\\n  .withColumn(\"timelist\", F.collect_list(F.col(\"time-started\").cast(\"long\")).over(w))\\\n  .withColumn(\"timelist2\", F.collect_list(F.when(F.col(\"diff\").isNotNull(),F.col(\"diff\")).otherwise(F.lit(0))).over(w))\\\n  .select(\"deviceId\",\"time-started\",\"packet1\",\"timelist\",\"timelist2\")\\\n    .withColumn(\"timelist2\", F.expr(\"\"\"transform(timelist2,(x,i)-> IF(i=0,0,x))\"\"\"))\\\n  .withColumn(\"agg\", F.expr(\"\"\"aggregate(timelist2, 0,(acc,t)->acc+int(t))\"\"\"))\\\n  .filter(\"deviceId='A'\").orderBy(\"time-started\"))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>deviceId</th><th>time-started</th><th>packet1</th><th>timelist</th><th>timelist2</th><th>agg</th></tr></thead><tbody><tr><td>A</td><td>2020-04-08T01:53:54.000+0000</td><td>8213496</td><td>List(1586310834, 1586313638, 1586382310, 1586391328)</td><td>List(0, 2804, 68672, 9018)</td><td>80494</td></tr><tr><td>A</td><td>2020-04-08T02:40:38.000+0000</td><td>7840779</td><td>List(1586313638, 1586382310, 1586391328)</td><td>List(0, 68672, 9018)</td><td>77690</td></tr><tr><td>A</td><td>2020-04-08T21:45:10.000+0000</td><td>8245057</td><td>List(1586382310, 1586391328, 1586406453, 1586406565, 1586407461, 1586407840)</td><td>List(0, 9018, 15125, 112, 896, 379)</td><td>25530</td></tr><tr><td>A</td><td>2020-04-09T00:15:28.000+0000</td><td>4795979</td><td>List(1586391328, 1586406453, 1586406565, 1586407461, 1586407840, 1586476850)</td><td>List(0, 15125, 112, 896, 379, 69010)</td><td>85522</td></tr><tr><td>A</td><td>2020-04-09T04:27:33.000+0000</td><td>1223887</td><td>List(1586406453, 1586406565, 1586407461, 1586407840, 1586476850, 1586492428)</td><td>List(0, 112, 896, 379, 69010, 15578)</td><td>85975</td></tr><tr><td>A</td><td>2020-04-09T04:29:25.000+0000</td><td>1223887</td><td>List(1586406565, 1586407461, 1586407840, 1586476850, 1586492428)</td><td>List(0, 896, 379, 69010, 15578)</td><td>85863</td></tr><tr><td>A</td><td>2020-04-09T04:44:21.000+0000</td><td>1216414</td><td>List(1586407461, 1586407840, 1586476850, 1586492428, 1586493095)</td><td>List(0, 379, 69010, 15578, 667)</td><td>85634</td></tr><tr><td>A</td><td>2020-04-09T04:50:40.000+0000</td><td>663058</td><td>List(1586407840, 1586476850, 1586492428, 1586493095)</td><td>List(0, 69010, 15578, 667)</td><td>85255</td></tr><tr><td>A</td><td>2020-04-10T00:00:50.000+0000</td><td>591</td><td>List(1586476850, 1586492428, 1586493095)</td><td>List(0, 15578, 667)</td><td>16245</td></tr><tr><td>A</td><td>2020-04-10T04:20:28.000+0000</td><td>519</td><td>List(1586492428, 1586493095)</td><td>List(0, 667)</td><td>667</td></tr><tr><td>A</td><td>2020-04-10T04:31:35.000+0000</td><td>22</td><td>List(1586493095)</td><td>List(0)</td><td>0</td></tr></tbody></table></div>"]}}],"execution_count":16},{"cell_type":"code","source":["x-> aggregate(timelist2, 0,(acc,t)->acc+t)"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["#`df.select('data_id',lpad(df['data'],length(df.data) +3 ,'p1/'))\n\nlist=[[1,'yo'],\n      [2,'dpppp']]\n\ndf=spark.createDataFrame(list,['data_id','data'])\n\n\ndf.select(\"data_id\",F.expr(\"\"\"lpad(data,length(data)+3,'p1/')\"\"\")).show()\n\ndf.select(\"data_id\",F.concat(F.lit('p1/'),F.col(\"data\"))).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+-----------------------------------+\ndata_id|lpad(data, (length(data) + 3), p1/)|\n+-------+-----------------------------------+\n      1|                              p1/yo|\n      2|                           p1/dpppp|\n+-------+-----------------------------------+\n\n+-------+-----------------+\ndata_id|concat(p1/, data)|\n+-------+-----------------+\n      1|            p1/yo|\n      2|         p1/dpppp|\n+-------+-----------------+\n\n</div>"]}}],"execution_count":18},{"cell_type":"code","source":["from pyspark.sql.functions import window\ndf1=df.withColumn(\"time-started\", F.to_timestamp(\"time-started\", \"yyyy-MM-dd'T'HH:mm:ss\"))\ndf1.groupBy(\"deviceId\",window(F.col(\"time-started\"),\"1 DAY\")).agg(F.sum(\"packet\")).show(truncate=False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+------------------------------------------+-----------+\ndeviceId|window                                    |sum(packet)|\n+--------+------------------------------------------+-----------+\nB       |[2020-04-08 00:00:00, 2020-04-09 00:00:00]|395565     |\nA       |[2020-04-09 00:00:00, 2020-04-10 00:00:00]|4795907    |\nA       |[2020-04-10 00:00:00, 2020-04-11 00:00:00]|591        |\nB       |[2020-04-09 00:00:00, 2020-04-10 00:00:00]|1961603    |\nB       |[2020-04-10 00:00:00, 2020-04-11 00:00:00]|497        |\nA       |[2020-04-08 00:00:00, 2020-04-09 00:00:00]|4640907    |\n+--------+------------------------------------------+-----------+\n\n</div>"]}}],"execution_count":19},{"cell_type":"code","source":["LIST=[['key1',None,None,'v1'],\n      [None,'key2',None,'v2'],\n      [None,None,'key3','v3'],\n      [None,'key4',None,'v4']]\n\ndf=spark.createDataFrame(LIST,['A','B','C','value'])\n\ndf.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----+----+----+-----+\n   A|   B|   C|value|\n+----+----+----+-----+\nkey1|null|null|   v1|\nnull|key2|null|   v2|\nnull|null|key3|   v3|\nnull|key4|null|   v4|\n+----+----+----+-----+\n\n</div>"]}}],"execution_count":20},{"cell_type":"code","source":["import pyspark.sql.functions as F\n\ncols = [i for i in df.columns if i!='value'] #['A','B','C']\n\noutput = df.select(F.greatest(*[F.when(F.col(i).isNotNull(),i)\n                             for i in cols]).alias(\"key_type\")\n               ,F.greatest(*[F.col(i) for i in cols]).alias(\"key_Value\"),\"value\")"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["import pyspark.sql.functions as F\n\ncols = [i for i in df.columns if i!='value'] #['A','B','C']\n\noutput = df.withColumn(\"key\",F.greatest(*[F.when(F.col(i).isNotNull(),F.array(F.lit(i),F.col(i))) for i in cols]).alias(\"key\")\\\n                      .select((F.col(\"key\")[0])\n               \noutput.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------+\n      key|\n+---------+\n[A, key1]|\n[B, key2]|\n[C, key3]|\n[B, key4]|\n+---------+\n\n</div>"]}}],"execution_count":22},{"cell_type":"code","source":["df.withColumn(\"key\",F.coalesce(*[(F.when(F.col(x).isNotNull(),F.array(F.lit(x),F.col(x)))).alias(x)\\\n                                 for x in df.columns if x!='value']))\\\n  .select((F.col(\"key\")[0]).alias(\"key_type\"),(F.col(\"key\")[1]).alias(\"key_value\"),F.col(\"value\")).show()\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+---------+-----+\nkey_type|key_value|value|\n+--------+---------+-----+\n       A|     key1|   v1|\n       B|     key2|   v2|\n       C|     key3|   v3|\n       B|     key4|   v4|\n+--------+---------+-----+\n\n</div>"]}}],"execution_count":23},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["df.withColumn(\"key\",F.coalesce(*[(F.when(F.col(x).isNotNull(),F.array(F.lit(x),F.col(x))).otherwise(None)).alias(x)\\\n                                 for x in df.columns if x!='value']))\\\n  .select((F.col(\"key\")[0]).alias(\"key_type\"),(F.col(\"key\")[1]).alias(\"key_value\"),F.col(\"value\")).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+---------+-----+\nkey_type|key_value|value|\n+--------+---------+-----+\n       A|     key1|   v1|\n       B|     key2|   v2|\n       C|     key3|   v3|\n       B|     key4|   v4|\n+--------+---------+-----+\n\n</div>"]}}],"execution_count":25},{"cell_type":"code","source":["  select(F.coalesce(*[\"A\",\"B\",\"C\"]).alias(\"key_value\")).show()"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["list=[[  1,40,50],\n      [  1,30,70],\n      [  2,10,91],\n      [  2,90,21],\n      [ 3,20,42],\n      [ 3,10,4],\n      [  4,2,23],\n      [ 4,5,12]]\n\ndf=spark.createDataFrame(list,['id','value1','value2'])\ndf.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+------+------+\n id|value1|value2|\n+---+------+------+\n  1|    40|    50|\n  1|    30|    70|\n  2|    10|    91|\n  2|    90|    21|\n  3|    20|    42|\n  3|    10|     4|\n  4|     2|    23|\n  4|     5|    12|\n+---+------+------+\n\n</div>"]}}],"execution_count":27},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["from pyspark.sql.window import Window\nfrom pyspark.sql import functions as F\n\nw = Window().partitionBy()\ndf.groupBy(\"id\").agg(F.sum(\"value1\").alias(\"grouped_total_1\"),F.sum(\"value2\").alias(\"grouped_total_2\"))\\\n          .withColumn(\"anti_grouped_total_1\",F.sum(\"grouped_total_1\").over(w)-F.col(\"grouped_total_1\"))\\\n          .withColumn(\"anti_grouped_total_2\",F.sum(\"grouped_total_2\").over(w)-F.col(\"grouped_total_2\")).orderBy(\"id\").show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+---------------+---------------+--------------------+--------------------+\n id|grouped_total_1|grouped_total_2|anti_grouped_total_1|anti_grouped_total_2|\n+---+---------------+---------------+--------------------+--------------------+\n  1|             70|            120|                 137|                 193|\n  2|            100|            112|                 107|                 201|\n  3|             30|             46|                 177|                 267|\n  4|              7|             35|                 200|                 278|\n+---+---------------+---------------+--------------------+--------------------+\n\n</div>"]}}],"execution_count":29},{"cell_type":"code","source":["list=[[1,'K'],\n      [1,'A'],\n       [1,'S'],\n       [2,'M'],\n       [2,'D'],\n       [2,'S'],\n       [3,'S'],\n       [3,'S'],\n       [4,'M'],\n       [5,'K'],\n       [1,'S'],\n       [6,'S']]\n\ndf=spark.createDataFrame(list,['account_no','types'])\n\ndf.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+-----+\naccount_no|types|\n+----------+-----+\n         1|    K|\n         1|    A|\n         1|    S|\n         2|    M|\n         2|    D|\n         2|    S|\n         3|    S|\n         3|    S|\n         4|    M|\n         5|    K|\n         1|    S|\n         6|    S|\n+----------+-----+\n\n</div>"]}}],"execution_count":30},{"cell_type":"code","source":["from pyspark.sql import functions as F\nfrom pyspark.sql.window import Window\n\nw=Window().partitionBy(\"account_no\")\nw1=Window().partitionBy(\"account_no\").orderBy(\"types\")\n\ndf.withColumn(\"sum_S\", F.sum(F.when(F.col(\"types\")=='S', F.lit(1)).otherwise(F.lit(0))).over(w))\\\n  .withColumn(\"total\", F.max(F.row_number().over(w1)).over(w))\\\n  .filter('total=sum_S').drop(\"total\",\"Sum_S\").show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+-----+\naccount_no|types|\n+----------+-----+\n         6|    S|\n         3|    S|\n         3|    S|\n+----------+-----+\n\n</div>"]}}],"execution_count":31},{"cell_type":"code","source":["w=Window().partitionBy(\"account_no\")\nw1=Window().partitionBy(\"account_no\").orderBy(\"types\")\n\ndf.withColumn(\"check_S\", F.when(F.col(\"types\")=='S', F.lit(1)).otherwise(F.lit(0)))\\\n  .withColumn(\"Sum_S\", F.sum(\"check_S\").over(w))\\\n  .withColumn(\"total\", F.max(F.row_number().over(w1)).over(w))\\\n  .filter('total=Sum_S').drop(\"check_S\",\"Sum_S\").show()"],"metadata":{},"outputs":[],"execution_count":32}],"metadata":{"name":"stackhelp48","notebookId":485056644424510},"nbformat":4,"nbformat_minor":0}
