{"cells":[{"cell_type":"code","source":["from pyspark.sql import functions as F \nfrom pyspark.sql.window import Window\nfrom pyspark.sql.types import *\nfrom pyspark.storagelevel import StorageLevel"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["list=[[0,'Town Street','01-02-2017 06:01:00'],\n      [0,'Town Street','01-02-2017 06:03:00'],\n      [0,'Town Street','01-02-2017 06:18:00'],\n      [0,'Town Street','01-02-2017 06:06:00'],\n      [0,'Town Street','02-02-2017 10:01:00'],\n      [0,'Town Street','02-02-2017 10:05:00']]\n\ndf=spark.createDataFrame(list,['col1','col2','timestamp'])\n\ndf.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----+-----------+-------------------+\ncol1|       col2|          timestamp|\n+----+-----------+-------------------+\n   0|Town Street|01-02-2017 06:01:00|\n   0|Town Street|01-02-2017 06:03:00|\n   0|Town Street|01-02-2017 06:05:00|\n   0|Town Street|01-02-2017 06:06:00|\n   0|Town Street|02-02-2017 10:01:00|\n   0|Town Street|02-02-2017 10:05:00|\n+----+-----------+-------------------+\n\n</div>"]}}],"execution_count":2},{"cell_type":"code","source":["from pyspark.sql import functions as F\nfrom pyspark.sql.window import Window\n\nw=Window().partitionBy(\"date\").orderBy(F.col(\"timestamp\").cast(\"long\")).rangeBetween(Window.currentRow,60*5)\n\ndf.withColumn(\"timestamp\", F.to_timestamp(\"timestamp\",'MM-dd-yyyy HH:mm:ss'))\\\n  .withColumn(\"date\", F.to_date(\"timestamp\"))\\\n  .withColumn('collect', F.size(F.collect_list(\"timestamp\").over(w))).filter(\"collect>1\")\\\n  .select(F.date_format(\"date\",\"yyyy-MM-dd\").alias(\"date\"), F.array(F.date_format(\"timestamp\",\"HH:mm:ss\"),F.col(\"collect\")).alias(\"time\"))\\\n  .orderBy(\"date\").show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+-------------+\n      date|         time|\n+----------+-------------+\n2017-01-02|[06:01:00, 4]|\n2017-01-02|[06:05:00, 2]|\n2017-01-02|[06:03:00, 3]|\n2017-02-02|[10:01:00, 2]|\n+----------+-------------+\n\n</div>"]}}],"execution_count":3},{"cell_type":"code","source":["list=[[[1,2,3,4]]]\n\ndf=spark.createDataFrame(list,['list'])\n\ndf.show(truncate=False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------------+\nlist        |\n+------------+\n[1, 2, 3, 4]|\n+------------+\n\n</div>"]}}],"execution_count":4},{"cell_type":"code","source":["df.withColumn(\"list2\", F.col(\"list\").getItem(0))\\\n  .withColumn(\"list3\", F.col(\"list\")[0])\\\n  .withColumn(\"list4\", F.element_at(\"list\", 1)).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------------+-----+-----+-----+\n        list|list2|list3|list4|\n+------------+-----+-----+-----+\n[1, 2, 3, 4]|    1|    1|    1|\n+------------+-----+-----+-----+\n\n</div>"]}}],"execution_count":5},{"cell_type":"code","source":["DEF= ['LB','LWB','RB','LCB','RCB','CB','RWB']\nFWD= ['RF','LF','LW','RS','RW','LS','CF','ST'] \nMID= ['LCM','LM','RDM','CAM','RAM','RCM','CM','CDM','RM','LAM','LDM'] \n\nlist=[['RF'],\n     ['RDM'],\n     ['CB']]\n\ndf=spark.createDataFrame(list,['Position'])\n\ndf.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+\nPosition|\n+--------+\n      RF|\n     RDM|\n      CB|\n+--------+\n\n</div>"]}}],"execution_count":6},{"cell_type":"code","source":["from pyspark.sql import functions as F\ndf.withColumn(\"Position_2\", F.when(F.col(\"Position\").rlike('RF$'),F.lit('DEF'))\\\n                             .when(F.col(\"Position\").rlike('RDM$'),F.lit('FWD'))\\\n                             .otherwise(F.lit('MID'))).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+----------+\nPosition|Position_2|\n+--------+----------+\n      RF|       DEF|\n     RDM|       FWD|\n      CB|       MID|\n+--------+----------+\n\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":["from pyspark.sql import functions as F\nfrom pyspark.sql.functions import when\n\nDEF= ['LB','LWB','RB','LCB','RCB','CB','RWB']\nFWD= ['RF','LF','LW','RS','RW','LS','CF','ST'] \nMID= ['LCM','LM','RDM','CAM','RAM','RCM','CM','CDM','RM','LAM','LDM'] \n\ndf.withColumn(\"DEF\", F.array(*[F.lit(x) for x in DEF]))\\\n  .withColumn(\"FWD\", F.array(*[F.lit(x) for x in FWD]))\\\n  .withColumn(\"Position_2\", F.when(F.expr(\"\"\"array_contains(DEF,Position)\"\"\")==True, F.lit('DEF'))\\\n                             .when(F.expr(\"\"\"array_contains(FWD,Position)\"\"\")==True, F.lit('FWD'))\\\n                              .otherwise(F.lit(\"MID\"))).drop(\"DEF\",\"MID\",\"FWD\").show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+----------+\nPosition|Position_2|\n+--------+----------+\n      RF|       FWD|\n     RDM|       MID|\n      CB|       DEF|\n+--------+----------+\n\n</div>"]}}],"execution_count":8},{"cell_type":"code","source":["df.withColumn(\"position_2\", F.when(F.arrays_overlap(F.array(*(F.lit(x) for x in DEF)),F.array(\"Position\")),F.lit('DEF'))\\\n                             .when(F.arrays_overlap(F.array(*(F.lit(x) for x in FWD)),F.array(\"Position\")),F.lit('FWD'))\\\n                             .otherwise(F.lit('MID'))).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+----------+\nPosition|position_2|\n+--------+----------+\n      RF|       FWD|\n     RDM|       MID|\n      CB|       DEF|\n+--------+----------+\n\n</div>"]}}],"execution_count":9},{"cell_type":"code","source":["list=[['b','7/1/2019',12,1],           \n      ['a','6/9/2019',0,5],           \n      ['c','1/1/2019',0,0]]  \n\ndf=spark.createDataFrame(list,['USER','DATE','COUNT_COL1','COUNT_COL2'])\n\ndf.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----+--------+----------+----------+\nUSER|    DATE|COUNT_COL1|COUNT_COL2|\n+----+--------+----------+----------+\n   b|7/1/2019|        12|         1|\n   a|6/9/2019|         0|         5|\n   c|1/1/2019|         0|         0|\n+----+--------+----------+----------+\n\n</div>"]}}],"execution_count":10},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["df.withColumn('cnt', F.sum((df[c[0]]>0).astype(\"int\") for c in df.dtypes if c[1] in ['int','long'])).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">Py4JError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-2954689015007897&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>df<span class=\"ansi-blue-fg\">.</span>withColumn<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;cnt&#39;</span><span class=\"ansi-blue-fg\">,</span> F<span class=\"ansi-blue-fg\">.</span>sum<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">(</span>df<span class=\"ansi-blue-fg\">[</span>c<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">0</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">&gt;</span><span class=\"ansi-cyan-fg\">0</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>astype<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;int&#34;</span><span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">for</span> c <span class=\"ansi-green-fg\">in</span> df<span class=\"ansi-blue-fg\">.</span>dtypes <span class=\"ansi-green-fg\">if</span> c<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-green-fg\">in</span> <span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">&#39;int&#39;</span><span class=\"ansi-blue-fg\">,</span><span class=\"ansi-blue-fg\">&#39;long&#39;</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/functions.py</span> in <span class=\"ansi-cyan-fg\">_</span><span class=\"ansi-blue-fg\">(col)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     42</span>     <span class=\"ansi-green-fg\">def</span> _<span class=\"ansi-blue-fg\">(</span>col<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     43</span>         sc <span class=\"ansi-blue-fg\">=</span> SparkContext<span class=\"ansi-blue-fg\">.</span>_active_spark_context\n<span class=\"ansi-green-fg\">---&gt; 44</span><span class=\"ansi-red-fg\">         </span>jc <span class=\"ansi-blue-fg\">=</span> getattr<span class=\"ansi-blue-fg\">(</span>sc<span class=\"ansi-blue-fg\">.</span>_jvm<span class=\"ansi-blue-fg\">.</span>functions<span class=\"ansi-blue-fg\">,</span> name<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">(</span>col<span class=\"ansi-blue-fg\">.</span>_jc <span class=\"ansi-green-fg\">if</span> isinstance<span class=\"ansi-blue-fg\">(</span>col<span class=\"ansi-blue-fg\">,</span> Column<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">else</span> col<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     45</span>         <span class=\"ansi-green-fg\">return</span> Column<span class=\"ansi-blue-fg\">(</span>jc<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     46</span>     _<span class=\"ansi-blue-fg\">.</span>__name__ <span class=\"ansi-blue-fg\">=</span> name\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1255</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1256</span>         return_value = get_return_value(\n<span class=\"ansi-green-fg\">-&gt; 1257</span><span class=\"ansi-red-fg\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1258</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1259</span>         <span class=\"ansi-green-fg\">for</span> temp_arg <span class=\"ansi-green-fg\">in</span> temp_args<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     61</span>     <span class=\"ansi-green-fg\">def</span> deco<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     62</span>         <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">---&gt; 63</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     64</span>         <span class=\"ansi-green-fg\">except</span> py4j<span class=\"ansi-blue-fg\">.</span>protocol<span class=\"ansi-blue-fg\">.</span>Py4JJavaError <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     65</span>             s <span class=\"ansi-blue-fg\">=</span> e<span class=\"ansi-blue-fg\">.</span>java_exception<span class=\"ansi-blue-fg\">.</span>toString<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py</span> in <span class=\"ansi-cyan-fg\">get_return_value</span><span class=\"ansi-blue-fg\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    330</span>                 raise Py4JError(\n<span class=\"ansi-green-intense-fg ansi-bold\">    331</span>                     <span class=\"ansi-blue-fg\">&#34;An error occurred while calling {0}{1}{2}. Trace:\\n{3}\\n&#34;</span><span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-fg\">--&gt; 332</span><span class=\"ansi-red-fg\">                     format(target_id, &#34;.&#34;, name, value))\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    333</span>         <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    334</span>             raise Py4JError(\n\n<span class=\"ansi-red-fg\">Py4JError</span>: An error occurred while calling z:org.apache.spark.sql.functions.sum. Trace:\npy4j.Py4JException: Method sum([class java.util.ArrayList]) does not exist\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:341)\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:362)\n\tat py4j.Gateway.invoke(Gateway.java:289)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\n\n</div>"]}}],"execution_count":12},{"cell_type":"code","source":["for i in df.dtypes:\n  print(i[0],i[1])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">USER string\nDATE string\nCOUNT_COL1 bigint\nCOUNT_COL2 bigint\n</div>"]}}],"execution_count":13},{"cell_type":"code","source":["\ndf.withColumn(\"arr\", F.array(*[F.col(i[0]) for i in df.dtypes if i[1] in ['int','bigint']]))\\\n  .withColumn(\"DESIRED COLUMN\", F.expr(\"\"\"size(filter(arr,x->x!=0))\"\"\")).drop(\"arr\").show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----+--------+----------+----------+--------------+\nUSER|    DATE|COUNT_COL1|COUNT_COL2|DESIRED COLUMN|\n+----+--------+----------+----------+--------------+\n   b|7/1/2019|        12|         1|             2|\n   a|6/9/2019|         0|         5|             1|\n   c|1/1/2019|         0|         0|             0|\n+----+--------+----------+----------+--------------+\n\n</div>"]}}],"execution_count":14},{"cell_type":"code","source":["df.withColumn(\"arr\", F.array(*[F.col(i[0]) for i in df.dtypes if i[1] in ['int','bigint']]))\\\n  .withColumn(\"DESIRED COLUMN\", F.expr(\"\"\"size(filter(arr,x->x!=0))\"\"\")).drop(\"arr\").show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">TypeError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3747450522555419&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> \n<span class=\"ansi-green-fg\">----&gt; 2</span><span class=\"ansi-red-fg\"> </span>df<span class=\"ansi-blue-fg\">.</span>withColumn<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;arr&#34;</span><span class=\"ansi-blue-fg\">,</span> F<span class=\"ansi-blue-fg\">.</span>sum<span class=\"ansi-blue-fg\">(</span>F<span class=\"ansi-blue-fg\">.</span>col<span class=\"ansi-blue-fg\">(</span>i<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">0</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">for</span> i <span class=\"ansi-green-fg\">in</span> df<span class=\"ansi-blue-fg\">.</span>dtypes <span class=\"ansi-green-fg\">if</span> i<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-green-fg\">in</span> <span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">&#39;int&#39;</span><span class=\"ansi-blue-fg\">,</span><span class=\"ansi-blue-fg\">&#39;bigint&#39;</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-red-fg\">\\</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span>   <span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/functions.py</span> in <span class=\"ansi-cyan-fg\">_</span><span class=\"ansi-blue-fg\">(col)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     42</span>     <span class=\"ansi-green-fg\">def</span> _<span class=\"ansi-blue-fg\">(</span>col<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     43</span>         sc <span class=\"ansi-blue-fg\">=</span> SparkContext<span class=\"ansi-blue-fg\">.</span>_active_spark_context\n<span class=\"ansi-green-fg\">---&gt; 44</span><span class=\"ansi-red-fg\">         </span>jc <span class=\"ansi-blue-fg\">=</span> getattr<span class=\"ansi-blue-fg\">(</span>sc<span class=\"ansi-blue-fg\">.</span>_jvm<span class=\"ansi-blue-fg\">.</span>functions<span class=\"ansi-blue-fg\">,</span> name<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">(</span>col<span class=\"ansi-blue-fg\">.</span>_jc <span class=\"ansi-green-fg\">if</span> isinstance<span class=\"ansi-blue-fg\">(</span>col<span class=\"ansi-blue-fg\">,</span> Column<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">else</span> col<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     45</span>         <span class=\"ansi-green-fg\">return</span> Column<span class=\"ansi-blue-fg\">(</span>jc<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     46</span>     _<span class=\"ansi-blue-fg\">.</span>__name__ <span class=\"ansi-blue-fg\">=</span> name\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1246</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1247</span>     <span class=\"ansi-green-fg\">def</span> __call__<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">*</span>args<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">-&gt; 1248</span><span class=\"ansi-red-fg\">         </span>args_command<span class=\"ansi-blue-fg\">,</span> temp_args <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_build_args<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>args<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1249</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1250</span>         command <span class=\"ansi-blue-fg\">=</span> proto<span class=\"ansi-blue-fg\">.</span>CALL_COMMAND_NAME <span class=\"ansi-blue-fg\">+</span><span class=\"ansi-red-fg\">\\</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">_build_args</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1210</span>     <span class=\"ansi-green-fg\">def</span> _build_args<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">*</span>args<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1211</span>         <span class=\"ansi-green-fg\">if</span> self<span class=\"ansi-blue-fg\">.</span>converters <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">not</span> <span class=\"ansi-green-fg\">None</span> <span class=\"ansi-green-fg\">and</span> len<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>converters<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">&gt;</span> <span class=\"ansi-cyan-fg\">0</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">-&gt; 1212</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-blue-fg\">(</span>new_args<span class=\"ansi-blue-fg\">,</span> temp_args<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_get_args<span class=\"ansi-blue-fg\">(</span>args<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1213</span>         <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1214</span>             new_args <span class=\"ansi-blue-fg\">=</span> args\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">_get_args</span><span class=\"ansi-blue-fg\">(self, args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1197</span>                 <span class=\"ansi-green-fg\">for</span> converter <span class=\"ansi-green-fg\">in</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>converters<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1198</span>                     <span class=\"ansi-green-fg\">if</span> converter<span class=\"ansi-blue-fg\">.</span>can_convert<span class=\"ansi-blue-fg\">(</span>arg<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">-&gt; 1199</span><span class=\"ansi-red-fg\">                         </span>temp_arg <span class=\"ansi-blue-fg\">=</span> converter<span class=\"ansi-blue-fg\">.</span>convert<span class=\"ansi-blue-fg\">(</span>arg<span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1200</span>                         temp_args<span class=\"ansi-blue-fg\">.</span>append<span class=\"ansi-blue-fg\">(</span>temp_arg<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1201</span>                         new_args<span class=\"ansi-blue-fg\">.</span>append<span class=\"ansi-blue-fg\">(</span>temp_arg<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_collections.py</span> in <span class=\"ansi-cyan-fg\">convert</span><span class=\"ansi-blue-fg\">(self, object, gateway_client)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    499</span>         java_list <span class=\"ansi-blue-fg\">=</span> ArrayList<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    500</span>         <span class=\"ansi-green-fg\">for</span> element <span class=\"ansi-green-fg\">in</span> object<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 501</span><span class=\"ansi-red-fg\">             </span>java_list<span class=\"ansi-blue-fg\">.</span>add<span class=\"ansi-blue-fg\">(</span>element<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    502</span>         <span class=\"ansi-green-fg\">return</span> java_list\n<span class=\"ansi-green-intense-fg ansi-bold\">    503</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1246</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1247</span>     <span class=\"ansi-green-fg\">def</span> __call__<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">*</span>args<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">-&gt; 1248</span><span class=\"ansi-red-fg\">         </span>args_command<span class=\"ansi-blue-fg\">,</span> temp_args <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_build_args<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>args<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1249</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1250</span>         command <span class=\"ansi-blue-fg\">=</span> proto<span class=\"ansi-blue-fg\">.</span>CALL_COMMAND_NAME <span class=\"ansi-blue-fg\">+</span><span class=\"ansi-red-fg\">\\</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">_build_args</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1210</span>     <span class=\"ansi-green-fg\">def</span> _build_args<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">*</span>args<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1211</span>         <span class=\"ansi-green-fg\">if</span> self<span class=\"ansi-blue-fg\">.</span>converters <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">not</span> <span class=\"ansi-green-fg\">None</span> <span class=\"ansi-green-fg\">and</span> len<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>converters<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">&gt;</span> <span class=\"ansi-cyan-fg\">0</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">-&gt; 1212</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-blue-fg\">(</span>new_args<span class=\"ansi-blue-fg\">,</span> temp_args<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_get_args<span class=\"ansi-blue-fg\">(</span>args<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1213</span>         <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1214</span>             new_args <span class=\"ansi-blue-fg\">=</span> args\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">_get_args</span><span class=\"ansi-blue-fg\">(self, args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1197</span>                 <span class=\"ansi-green-fg\">for</span> converter <span class=\"ansi-green-fg\">in</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>converters<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1198</span>                     <span class=\"ansi-green-fg\">if</span> converter<span class=\"ansi-blue-fg\">.</span>can_convert<span class=\"ansi-blue-fg\">(</span>arg<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">-&gt; 1199</span><span class=\"ansi-red-fg\">                         </span>temp_arg <span class=\"ansi-blue-fg\">=</span> converter<span class=\"ansi-blue-fg\">.</span>convert<span class=\"ansi-blue-fg\">(</span>arg<span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1200</span>                         temp_args<span class=\"ansi-blue-fg\">.</span>append<span class=\"ansi-blue-fg\">(</span>temp_arg<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1201</span>                         new_args<span class=\"ansi-blue-fg\">.</span>append<span class=\"ansi-blue-fg\">(</span>temp_arg<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_collections.py</span> in <span class=\"ansi-cyan-fg\">convert</span><span class=\"ansi-blue-fg\">(self, object, gateway_client)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    498</span>         ArrayList <span class=\"ansi-blue-fg\">=</span> JavaClass<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;java.util.ArrayList&#34;</span><span class=\"ansi-blue-fg\">,</span> gateway_client<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    499</span>         java_list <span class=\"ansi-blue-fg\">=</span> ArrayList<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">--&gt; 500</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">for</span> element <span class=\"ansi-green-fg\">in</span> object<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    501</span>             java_list<span class=\"ansi-blue-fg\">.</span>add<span class=\"ansi-blue-fg\">(</span>element<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    502</span>         <span class=\"ansi-green-fg\">return</span> java_list\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/column.py</span> in <span class=\"ansi-cyan-fg\">__iter__</span><span class=\"ansi-blue-fg\">(self)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    342</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    343</span>     <span class=\"ansi-green-fg\">def</span> __iter__<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 344</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">raise</span> TypeError<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;Column is not iterable&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    345</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    346</span>     <span class=\"ansi-red-fg\"># string methods</span>\n\n<span class=\"ansi-red-fg\">TypeError</span>: Column is not iterable</div>"]}}],"execution_count":15},{"cell_type":"code","source":["df.select(F.isnan(\"COUNT_COL1\")).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------------+\nisnan(COUNT_COL1)|\n+-----------------+\n            false|\n            false|\n            false|\n+-----------------+\n\n</div>"]}}],"execution_count":16},{"cell_type":"code","source":["df.withColumn('cnt', F.sum((df[c[0]]>0).astype(\"int\") for c in df.dtypes if c[1] in ['int','long'])).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">Py4JError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-2954689015007896&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>df<span class=\"ansi-blue-fg\">.</span>withColumn<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;cnt&#39;</span><span class=\"ansi-blue-fg\">,</span> F<span class=\"ansi-blue-fg\">.</span>sum<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">(</span>df<span class=\"ansi-blue-fg\">[</span>c<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">0</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">&gt;</span><span class=\"ansi-cyan-fg\">0</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>astype<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;int&#34;</span><span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">for</span> c <span class=\"ansi-green-fg\">in</span> df<span class=\"ansi-blue-fg\">.</span>dtypes <span class=\"ansi-green-fg\">if</span> c<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-green-fg\">in</span> <span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">&#39;int&#39;</span><span class=\"ansi-blue-fg\">,</span><span class=\"ansi-blue-fg\">&#39;long&#39;</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/functions.py</span> in <span class=\"ansi-cyan-fg\">_</span><span class=\"ansi-blue-fg\">(col)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     42</span>     <span class=\"ansi-green-fg\">def</span> _<span class=\"ansi-blue-fg\">(</span>col<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     43</span>         sc <span class=\"ansi-blue-fg\">=</span> SparkContext<span class=\"ansi-blue-fg\">.</span>_active_spark_context\n<span class=\"ansi-green-fg\">---&gt; 44</span><span class=\"ansi-red-fg\">         </span>jc <span class=\"ansi-blue-fg\">=</span> getattr<span class=\"ansi-blue-fg\">(</span>sc<span class=\"ansi-blue-fg\">.</span>_jvm<span class=\"ansi-blue-fg\">.</span>functions<span class=\"ansi-blue-fg\">,</span> name<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">(</span>col<span class=\"ansi-blue-fg\">.</span>_jc <span class=\"ansi-green-fg\">if</span> isinstance<span class=\"ansi-blue-fg\">(</span>col<span class=\"ansi-blue-fg\">,</span> Column<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">else</span> col<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     45</span>         <span class=\"ansi-green-fg\">return</span> Column<span class=\"ansi-blue-fg\">(</span>jc<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     46</span>     _<span class=\"ansi-blue-fg\">.</span>__name__ <span class=\"ansi-blue-fg\">=</span> name\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1255</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1256</span>         return_value = get_return_value(\n<span class=\"ansi-green-fg\">-&gt; 1257</span><span class=\"ansi-red-fg\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1258</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1259</span>         <span class=\"ansi-green-fg\">for</span> temp_arg <span class=\"ansi-green-fg\">in</span> temp_args<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     61</span>     <span class=\"ansi-green-fg\">def</span> deco<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     62</span>         <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">---&gt; 63</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     64</span>         <span class=\"ansi-green-fg\">except</span> py4j<span class=\"ansi-blue-fg\">.</span>protocol<span class=\"ansi-blue-fg\">.</span>Py4JJavaError <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     65</span>             s <span class=\"ansi-blue-fg\">=</span> e<span class=\"ansi-blue-fg\">.</span>java_exception<span class=\"ansi-blue-fg\">.</span>toString<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py</span> in <span class=\"ansi-cyan-fg\">get_return_value</span><span class=\"ansi-blue-fg\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    330</span>                 raise Py4JError(\n<span class=\"ansi-green-intense-fg ansi-bold\">    331</span>                     <span class=\"ansi-blue-fg\">&#34;An error occurred while calling {0}{1}{2}. Trace:\\n{3}\\n&#34;</span><span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-fg\">--&gt; 332</span><span class=\"ansi-red-fg\">                     format(target_id, &#34;.&#34;, name, value))\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    333</span>         <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    334</span>             raise Py4JError(\n\n<span class=\"ansi-red-fg\">Py4JError</span>: An error occurred while calling z:org.apache.spark.sql.functions.sum. Trace:\npy4j.Py4JException: Method sum([class java.util.ArrayList]) does not exist\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:341)\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:362)\n\tat py4j.Gateway.invoke(Gateway.java:289)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\n\n</div>"]}}],"execution_count":17},{"cell_type":"code","source":["df=spark.createDataFrame([(1,5,\"This\"),(2,10,\"is\"),(3,12,\"a\"),(1,7,\"string\"),(2,4,\"oreo\")],[\"usr\",\"sec\",\"scrpt\"])\ndf.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+---+------+\nusr|sec| scrpt|\n+---+---+------+\n  1|  5|  This|\n  2| 10|    is|\n  3| 12|     a|\n  1|  7|string|\n  2|  4|  oreo|\n+---+---+------+\n\n</div>"]}}],"execution_count":18},{"cell_type":"code","source":["df.groupBy(\"usr\").agg(F.sort_array(F.collect_list(F.struct(\"sec\",\"scrpt\"))).alias(\"concated\")).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+--------------------+\nusr|            concated|\n+---+--------------------+\n  1|[[5, This], [7, s...|\n  3|           [[12, a]]|\n  2|[[4, oreo], [10, ...|\n+---+--------------------+\n\n</div>"]}}],"execution_count":19},{"cell_type":"code","source":["df.groupBy(\"usr\").agg(F.array_join(F.expr(\"\"\"transform(sort_array(collect_list(struct(sec,scrpt)),True), x -> x.scrpt)\"\"\"),\" \").alias(\"concated\")).orderBy(\"usr\").show(10,False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+-----------+\nusr|concated   |\n+---+-----------+\n1  |This string|\n2  |oreo is    |\n3  |a          |\n+---+-----------+\n\n</div>"]}}],"execution_count":20},{"cell_type":"code","source":["list=[[ 1, 0],\n        [1,  1],\n        [1,  1],\n        [1,  0],\n        [1,  1],\n        [1,  1],\n        [2,  1],\n        [2,  1],\n        [3,  0],\n        [3,  1],\n        [3,  1],\n        [3,  1]]\n\ndf=spark.createDataFrame(list,['A','B'])\n\ndf.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+---+\n  A|  B|\n+---+---+\n  1|  0|\n  1|  1|\n  1|  1|\n  1|  0|\n  1|  1|\n  1|  1|\n  2|  1|\n  2|  1|\n  3|  0|\n  3|  1|\n  3|  1|\n  3|  1|\n+---+---+\n\n</div>"]}}],"execution_count":21},{"cell_type":"code","source":["from pyspark.sql import functions as F\nfrom pyspark.sql.window import Window\n\nw=Window().partitionBy(\"A\").orderBy(\"A\")\nw2=Window().partitionBy(\"C\").orderBy(\"A\")\ndf.withColumn(\"C\", F.sum(F.when(F.col(\"B\")==F.lit(0), F.lit(1)).otherwise(F.lit(0))).over(w))\\\n  .withColumn(\"C\", F.row_number().over(w2)).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+---+---+\n  A|  B|  C|\n+---+---+---+\n  2|  1|  1|\n  2|  1|  2|\n  3|  0|  1|\n  3|  1|  2|\n  3|  1|  3|\n  3|  1|  4|\n  1|  0|  1|\n  1|  1|  2|\n  1|  1|  3|\n  1|  0|  4|\n  1|  1|  5|\n  1|  1|  6|\n+---+---+---+\n\n</div>"]}}],"execution_count":22},{"cell_type":"code","source":["\n    +---+---+---+\n    |  A|  B|  C|\n    +---+---+---+\n    |  1|  0|  1|\n    |  1|  1|  2|\n    |  1|  1|  3|\n    |  1|  0|  4|\n    |  1|  1|  5|\n    |  1|  1|  6|\n    |  3|  0|  1|\n    |  3|  1|  2|\n    |  3|  1|  3|\n    |  3|  1|  4|\n    |  2|  1|  1|\n    |  2|  1|  2|\n    +---+---+---+"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["list= [v1     |2012-01-10| [5,2] |\n      [v1     |2012-01-11| [2,5] |\n      [v1     |2012-01-12| [3,2] |\n      [v2     |2012-01-12| [2]   |\n       v2     |2012-01-11| [1,2] |\n| v2     |2012-01-13| [1]   |\n+--------+----------+-------+"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["list=[[[5,2]],\n      [[2,5]],\n     [[2]]]\n\ndf=spark.createDataFrame(list,['list'])\n\ndf.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+\n  list|\n+------+\n[5, 2]|\n[2, 5]|\n   [2]|\n+------+\n\n</div>"]}}],"execution_count":25},{"cell_type":"code","source":["df.withColumn(\"diff\", F.when(F.size('list')==2, F.expr(\"\"\"transform(array(list),x-> x[0]-x[1])\"\"\")[0])\\\n                       .otherwise(F.lit(0))).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+----+\n  list|diff|\n+------+----+\n[5, 2]|   3|\n[2, 5]|  -3|\n   [2]|   0|\n+------+----+\n\n</div>"]}}],"execution_count":26},{"cell_type":"code","source":["list=[[[['componenţa', 'parlamentului:', 'a', 'se', 'vedea', 'procesul-verbal'],['membership', 'of', 'parliament:', 'see', 'minutes']]]]\n\ndf=spark.createDataFrame(list,['list'])\n\ndf.show(truncate=False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------------------------------------------------------------------------------------------------------+\nlist                                                                                                      |\n+----------------------------------------------------------------------------------------------------------+\n[[componenţa, parlamentului:, a, se, vedea, procesul-verbal], [membership, of, parliament:, see, minutes]]|\n+----------------------------------------------------------------------------------------------------------+\n\n</div>"]}}],"execution_count":27},{"cell_type":"code","source":["df.withColumn(\"list\", F.expr(\"\"\"transform(list,x-> filter(x, y-> y!='vedea'))\"\"\")).show(truncate=False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------------------------------------------------------------------------------------------------+\nlist                                                                                               |\n+---------------------------------------------------------------------------------------------------+\n[[componenţa, parlamentului:, a, se, procesul-verbal], [membership, of, parliament:, see, minutes]]|\n+---------------------------------------------------------------------------------------------------+\n\n</div>"]}}],"execution_count":28},{"cell_type":"code","source":["df.withColumn(\"list\",\\\nF.expr(\"\"\"filter(list,x-> array_contains(x,'vedea')!=True)\"\"\")).show(truncate=False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------------------------------------------+\nlist                                         |\n+---------------------------------------------+\n[[membership, of, parliament:, see, minutes]]|\n+---------------------------------------------+\n\n</div>"]}}],"execution_count":29},{"cell_type":"code","source":["df.withColumn(\"list\", F.expr(\"\"\"filter(list,x-> IF(array_contains(x,'vedea'),array_remove(list,x),array(x)))\"\"\")).show(truncate=False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     62</span>         <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">---&gt; 63</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     64</span>         <span class=\"ansi-green-fg\">except</span> py4j<span class=\"ansi-blue-fg\">.</span>protocol<span class=\"ansi-blue-fg\">.</span>Py4JJavaError <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py</span> in <span class=\"ansi-cyan-fg\">get_return_value</span><span class=\"ansi-blue-fg\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    327</span>                     <span class=\"ansi-blue-fg\">&#34;An error occurred while calling {0}{1}{2}.\\n&#34;</span><span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-fg\">--&gt; 328</span><span class=\"ansi-red-fg\">                     format(target_id, &#34;.&#34;, name), value)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    329</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-red-fg\">Py4JJavaError</span>: An error occurred while calling o1072.withColumn.\n: org.apache.spark.sql.AnalysisException: cannot resolve &#39;filter(`list`, lambdafunction((IF(array_contains(namedlambdavariable(), &#39;vedea&#39;), array_remove(`list`, namedlambdavariable()), array(namedlambdavariable()))), namedlambdavariable()))&#39; due to data type mismatch: argument 2 requires boolean type, however, &#39;lambdafunction((IF(array_contains(namedlambdavariable(), &#39;vedea&#39;), array_remove(`list`, namedlambdavariable()), array(namedlambdavariable()))), namedlambdavariable())&#39; is of array&lt;array&lt;string&gt;&gt; type.;;\nProject [filter(list#380, lambdafunction(if (array_contains(lambda x#400, vedea)) array_remove(list#380, lambda x#400) else array(lambda x#400), lambda x#400, false)) AS list#399]\n+- LogicalRDD [list#380], false\n\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$3.applyOrElse(CheckAnalysis.scala:126)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$3.applyOrElse(CheckAnalysis.scala:111)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$6.apply(TreeNode.scala:303)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$6.apply(TreeNode.scala:303)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:76)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:302)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$5.apply(TreeNode.scala:300)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$5.apply(TreeNode.scala:300)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$8.apply(TreeNode.scala:353)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:207)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:351)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:300)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:94)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:94)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$3.apply(QueryPlan.scala:106)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$3.apply(QueryPlan.scala:106)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:76)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:105)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:117)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1$2.apply(QueryPlan.scala:122)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.immutable.List.map(List.scala:296)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:122)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$4.apply(QueryPlan.scala:127)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:207)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:127)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:94)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:111)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:89)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:147)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$class.checkAnalysis(CheckAnalysis.scala:89)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:103)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:117)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:114)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:114)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$analyzed$1.apply(QueryExecution.scala:86)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$analyzed$1.apply(QueryExecution.scala:83)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:83)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:83)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:75)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:81)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withPlan(Dataset.scala:3534)\n\tat org.apache.spark.sql.Dataset.select(Dataset.scala:1362)\n\tat org.apache.spark.sql.Dataset.withColumns(Dataset.scala:2327)\n\tat org.apache.spark.sql.Dataset.withColumn(Dataset.scala:2294)\n\tat sun.reflect.GeneratedMethodAccessor419.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\n\n\nDuring handling of the above exception, another exception occurred:\n\n<span class=\"ansi-red-fg\">AnalysisException</span>                         Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-2854679527957179&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>df<span class=\"ansi-blue-fg\">.</span>withColumn<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;list&#34;</span><span class=\"ansi-blue-fg\">,</span> F<span class=\"ansi-blue-fg\">.</span>expr<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;&#34;&#34;filter(list,x-&gt; IF(array_contains(x,&#39;vedea&#39;),array_remove(list,x),array(x)))&#34;&#34;&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span>truncate<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-green-fg\">False</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/dataframe.py</span> in <span class=\"ansi-cyan-fg\">withColumn</span><span class=\"ansi-blue-fg\">(self, colName, col)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   2023</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-intense-fg ansi-bold\">   2024</span>         <span class=\"ansi-green-fg\">assert</span> isinstance<span class=\"ansi-blue-fg\">(</span>col<span class=\"ansi-blue-fg\">,</span> Column<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;col should be Column&#34;</span>\n<span class=\"ansi-green-fg\">-&gt; 2025</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> DataFrame<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jdf<span class=\"ansi-blue-fg\">.</span>withColumn<span class=\"ansi-blue-fg\">(</span>colName<span class=\"ansi-blue-fg\">,</span> col<span class=\"ansi-blue-fg\">.</span>_jc<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>sql_ctx<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   2026</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   2027</span>     <span class=\"ansi-blue-fg\">@</span>ignore_unicode_prefix\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1255</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1256</span>         return_value = get_return_value(\n<span class=\"ansi-green-fg\">-&gt; 1257</span><span class=\"ansi-red-fg\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1258</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1259</span>         <span class=\"ansi-green-fg\">for</span> temp_arg <span class=\"ansi-green-fg\">in</span> temp_args<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     67</span>                                              e.java_exception.getStackTrace()))\n<span class=\"ansi-green-intense-fg ansi-bold\">     68</span>             <span class=\"ansi-green-fg\">if</span> s<span class=\"ansi-blue-fg\">.</span>startswith<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;org.apache.spark.sql.AnalysisException: &#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">---&gt; 69</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">raise</span> AnalysisException<span class=\"ansi-blue-fg\">(</span>s<span class=\"ansi-blue-fg\">.</span>split<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;: &#39;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> stackTrace<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     70</span>             <span class=\"ansi-green-fg\">if</span> s<span class=\"ansi-blue-fg\">.</span>startswith<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;org.apache.spark.sql.catalyst.analysis&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     71</span>                 <span class=\"ansi-green-fg\">raise</span> AnalysisException<span class=\"ansi-blue-fg\">(</span>s<span class=\"ansi-blue-fg\">.</span>split<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;: &#39;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> stackTrace<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">AnalysisException</span>: &#34;cannot resolve &#39;filter(`list`, lambdafunction((IF(array_contains(namedlambdavariable(), &#39;vedea&#39;), array_remove(`list`, namedlambdavariable()), array(namedlambdavariable()))), namedlambdavariable()))&#39; due to data type mismatch: argument 2 requires boolean type, however, &#39;lambdafunction((IF(array_contains(namedlambdavariable(), &#39;vedea&#39;), array_remove(`list`, namedlambdavariable()), array(namedlambdavariable()))), namedlambdavariable())&#39; is of array&lt;array&lt;string&gt;&gt; type.;;\\nProject [filter(list#380, lambdafunction(if (array_contains(lambda x#400, vedea)) array_remove(list#380, lambda x#400) else array(lambda x#400), lambda x#400, false)) AS list#399]\\n+- LogicalRDD [list#380], false\\n&#34;</div>"]}}],"execution_count":30},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":31}],"metadata":{"name":"stackhelp50","notebookId":1918196788877808},"nbformat":4,"nbformat_minor":0}
